here but we'll go back okay nothing under data sources nothing under indexers but we' created our index what I was hoping to say was the structure there um maybe we go add adjacent maybe we show it here and so yeah so we can see our Fields here it's just it's just not visually shown anywhere else okay so so far that is good um but have we inserted our data yet I don't think so but let's continue on okay so yeah insert the text embedding into the vector store so add the text and metadata from Json data to the vector store so we grab this next I told you I don't like to do our Imports like this but that's just how they're doing it so we're going to stick with it so upload some documents to the index we'll just copy this whole part here and here I'm going to just take this out because it's just plain here so we're going to get its output path it might give us some issues here so I'm just going to do this again just in case this just means this the current directory so just kind of cheating there and then it's going to read the file as a document and it's going to do search client and we're going to have a search client and then we're going to upload the documents which is just all that Json data um it doesn't look like we're splitting it it's just loading them just loading the Json so let's give that a go there we go so so far so good this is not always the case like sometimes I'm working with uh I'm just saying like some whoa my head's really angled up here but yeah sometimes I'm working with um Azure examples and they don't work most of the time but this one has been pretty good but I'm thinking the reason why is that it's just more recent so anyway let's continue on um so now we have uploaded our documents now can we see where those are I don't think we would see it here if we go back into the search here I mean I would expect that we'd have to have a data source if we're sourcing data from there so I'm not sure where it is in the UI because the way I understand is like you have a data source so you connect to it but that's okay so here it says search client uh upload documents insert text and embeddings into the vector store okay well I want to know the vector store so give me a second I'm going to look up where it is so it says it has a vector store um it's not like Cosmo DB or anything in particular it's just part of the service I guess so not 100% certain on that one that's totally fine um not worried about it but uh you know just sometimes I like to visually see things so if you're indexing a very large number of documents we not um you can use the search index buffering Center which is an optimized way to automatically index the docs as it will handle it free B cing so something that we could have done instead we are I not doing that because I don't feel like we need to do that and we've already uploaded them so we're just going to ignore that so it says perform a vector similarity search so the idea is that our data is in here how it's in here I do not know I really thought that we'd have to connect um a data source but I guess it's just there let's go back here get to it oh you know what I didn't notice this before there's our Fields there we go okay I was going to the Json there probably like Andrew what is wrong with you I'm sorry the UI is just hard to look at um so we have that cores I guess if this is external our configuration which we created and our Vector profile we can't see our data here just yet but we're just going to uh continue on here so let's go back over to here and so here we can form a vectorized query okay so let's give it a go so grab this next I'm just going to grab this whole section because this has been pretty reliable so far and I realize my font's a little bit small I'm going to jump this up here I apologize for that entire time happy small font so um here we have a pure Vector search so we're providing it text and then for from that query we're creating an embedding so I'm assuming that's using the open AI way of embedding that data okay and then we provide that embedding we tell the nearest neighbors so how like how many friends or neighbors do we want to look out to and then we're looking across the content Vector so the vectors are going to match against the vectors and it's going to return the vector query which will then uh allow us to utilize that in our actual search and then we're going to select this information information that we want and print them out so go ahead and do that and so there we are getting our results back so that is very cool okay um I still would like to know how we do it here oh we just write whatever we want okay so this I was thinking there was like something really complex there but it seems seems like we could just uh what was do this as well we might get similar results let's just try this search so we have Azure devops developer tools I mean it's returning everything maybe there's like more ways we could filter information here I don't know but here you can see way more information so I guess that's just like a really easy way to find information okay but if we go back to here um it looked like there could have been an easier way to search no it doesn't really look like it that's fine all right so let's go back here and just continue on so clearly we did a vector search which wasn't too bad so now we have perform we hold on this this is perform a vector similarity search so things return things that are similar to to other things right and let's just take a look and see how similar it is tools for software development so Azure devops Azure devops Labs test very clear that that is that is there and it's giving us a score how close it is this one more than the other ones perform a vector similarity search using a vectorizable text query so this example shows a pure Vector search using the vectorizable text query all you need to do is pass in the text and your vectorizer will handle the rest okay so let's grab this and then we'll look at the code we'll try to see if we can make sense of it okay so go here next so this looks very similar the only difference is this one says vectorizable text search and this one say says vectorizable quer search and here we have to create the embedding and then do the vector query but here it looks like we are saving a step so um that's the only difference that it looks like it's doing we're getting the exact same results so yeah vectorizable text query so yeah I think it's just skipping a step and so we don't have to use that now we told it earlier that we wanted to use open ai's method of vectorizing so maybe that's what it's doing like when we pre-loaded earlier then this one is using that one that we loaded earlier on okay so this is example shows a pure Vector search demonstrating the open a API text embeddings a O2 multilingual capabilities let's take a look here um so okay so the question is we're not using Ada we're using the other one and so this is suggesting that if we use a different language that it's still going to figure it out so this might not work because we do not have that Library embedded I'm going to find out and see what happens okay and it still works but I just don't have confidence if it's using the actual um uh one that we're using but it's interesting that it can go across languages there so this is working supposedly but it could have been just tools was enough for it to know we look at these scores 058 057 054 I mean we're getting the same score so must be good but this here confuses me so I'm not sure what's going on there so now we have perform an exhaust of KN andn exact nearest neighbor search so we'll give that a go let's paste that in here we'll run that so it's using the vectorizable text search and we what's different let's go back here you see exhaustive equals true that's the only difference that I see here is that it's saying exhaustive is true oh well I guess it is how you can exhaustively search your vector index regardless of what index you have okay I see all right um then we have perform a cross field Vector search so this example shows a cross field Vector search that allows you to query multiple Vector fields at the same time note ensure the same embedding model was used for the vector Fields uh you decide to query okay so let's grab this one they're looking a whole lot similar to me but clearly there are differences here I'm not that well versed in these type of query things um I am creating lecture slides after these Labs um so if I do figure that out I'll put them in there and you'll we'll come to this video and we'll already know what it is at least you will me right now I do not know so we look at this one here and we're going to run it and it works let's go back here Cross Field Vector search so it says Cross Field allows you to query multiple Vector fields at the same time ah okay so here we're doing multiple Fields is what it's telling us okay and our results are a little a little bit different way different but I guess because now it's going across content it has more to pull from or if it if it was title so now we have a multi Vector search so shows a cross field Vector search that allows you to query multiple Vector fields at the same time by passing in multiple query vectors okay so now we are vectorizing twice but one for the title one for the content okay let's do that let's try this we'll run this that and I mean we're getting different results but it's stringing as one I'm not sure how it decides between the two but it does that apparently perform a weighted multiv Vector search so give one more weight than the other makes sense so run this looks good perform a pure Vector search with a filter so this example shows how to uh apply filters in your index whether you want to do pre filtering so let's take a look here where is the filter so we have Vector filter mode okay and then we're just saying pre-filter all right but what does that do that's what I want to know so it goes here and it says determines whether or not filters are applied before or after the vector search okay but what is it filtering oh right here so here's the filter so catalog equals developer tools all right so there's some query language or some filter language that we can utilize here um so we'll grab this and we'll run this we'll take a look and here it's saying category equals developer tool so it's filtering for that is that what we had in our data and we did okay so that's that's interesting okay that's cool we'll go down here below and we'll look at our next step here so now we're getting to more interesting things like hybrid search before um reranking search Hybrid search was the one that was really good um so here we will copy this and we'll take a look and see what's happening so we have the same thing we're vectorizing this information we have a query query vector but what makes this a hybrid search I'll H run here okay but what makes it hybrid because it looks very similar to the other ones is it because there's spaces in between here H so I'm not sure that's the only thing that's changing is this and this looks just like the other ones but apparently we can wait it we have a pretty good idea how waiting works so we're not going to run that one semantic hybrid search now we're getting into something interesting so this is the one that's supposed to be really really good so let's go copy this yeah I think uh when I go create the lecture content I will go f figure out what they mean by hybrid search here because I'm not 100% certain Al all the other ones previously were hybrid search so here we're saying what is aure sarch maybe that's a spelling mistake and that's intentional um so it's exhaustive equals true and down below here we have query type as semantic and it's using the semantic configuration which is what we have ours called here and then we have our semantic ancers let's go ahead and run that semantic answer okay and we have our score down here below and then the resources here okay well that's something and that's it okay so I'm not saying I understand what all of these searches do but I will Circle back put in the lecture content and then um I'll sound d dumb here but I'll sound smart in the other area there's clearly a lot of other things that we can do chunking might be something we might be interested in doing um working with an external data source is something we probably want to do let's just take a peek here into um this one I'm not sure if we want to do this so this one says demonstrate how to use Azure search Advance query rewriting to improve the relevance of your search so we'll take a look here and just see what we have so I'm just trying to see what is different we have chunking going on here okay so I'm not sure I might come back here and do another one um yeah I think we're going to do another one of these I'll do it in a separate video here I just want to take a look at the the chunking example here I'm just going to pause here and make a decision okay all right so this one's kind of interesting because um I was looking at the advanced one again and they're making a query and then they're feeding into a large language model saying hey can you make this query more efficient and then uh it's doing that query I think chunking is something that I uh think that we probably we could do but really all it's doing is it's just taking a um like a larger file like a PDF and you're just breaking up into parts so I don't know I feel like this is good enough um it'd be nice if we used Azure AI search with a data store I think that's something that we'll end up doing when we uh use Azure AI Studio or open AI studio so I think we're actually done here um and we got some practical experience here with it so this is fine I'm going to go up to the top here I'm going just clear these out nothing super exciting with this one as clearly we really stuck to the um sample for once we go here and just clear out these values here so that you know whoops that you know that uh you can't use the same one here okay I'm going to go ahead and just restart the kernel and I'm going to go ahead and download these files and so I'm going to go over to our Azure repo let github.com add your examples we'll press period here I'm I'm going to drag them over and so if you just want to run these and not fill around with things you can absolutely do that of course you don't know that until the end of the video but that's always the case here we'll say Azure AI search but uh yeah it'd be again it'd be nice if we had few other things here to do with the AI search because we obviously have data data sources and there's also skill sets so that's another thing that we could have uh took a look at so this is skills that you can add here but anyway we do talk about that in the lecture content I already have slides for that but um yeah we'll just upload this in place and then we'll just clean up here and be in good shape so here have my Azure AI search I'm going to go to my downloads off screen here here and drag them on over these three files over here Azure AI search and we will commit and push that and now that is done I'm going to go over to our portal here and I'm going to go into our Resource Group here this is our Resource Group and these are our two resources the search and open Ai and we'll go ahead and delete these resources okay and then uh yeah we'll delete that and then I'm just going to go ahead and shut this down there we go and I will see you in the next one okay ciao hey this is Andrew Brown in this video we're going to take a look at how we can use azrai search with our chat llm which is going to give us basically rag so let's go over here to um our chat playground and um the idea is that we have the ability to add data and so by adding data we're going to be able to provide this um chat bot with context now if we're using GPT 35 turbo it doesn't have the latest data so if we go ahead here and just say uh what is the latest data set uh that GPT 35 turbo is trained on I don't know if they they like update this model or if it just has the data that it has let's find out I don't have real time sure you okay so let's go ahead and say uh GPT 35 turbo um latest data set and it says here June 13 2024 so it seems like oh it says will be shut down created will uh will continue updates through 2023 the architecture Al alterations performed in 2023 will be shut down so what does that mean is that getting rid of Turbo so here we have um much more truthful also need for gp4 also detailing the course declines and API programat ability so we offer sta models the promise is broken what what are we hearing here so MH ah okay so it's I think it's suggesting to say like it has training data from 2021 but they're not doing anything um as of new with it but we could go ahead and just try to ass it something that is recent so I'm just trying to think of something that is recent um in the Azure space so what products has azure launched in 2023 let's see if it knows that okay what products has Azure launched in 2022 oh I did 2023 again let's go here 2022 2021 okay so this makes me think that it was trained on data from 2021 so if we pull anything that is newer let's go over to the Microsoft log and we'll go over to here and see if we can find something that is new let's go over to the AI blog and so I'm looking for technical announcements this is not really the best place to look I suppose it'll go back over to here usually they have like a developer form so maybe we'll say like um updated pricing for Azure a not Azure fine tuning uh AI Studio because that is something that I know that has changed here so yeah this article here zoom out here a bit this one talks about the new pricing changes for um for this and so we'll go here and so we say we're updating our building find tuning for Azure open search service this is going to take effect probably for Azure AI Service as well um so say you know we go here and say what is the current cost to um find tune a model on Azure AI open search and this is a feature that didn't even exist back then so it's probably not going to be able to do anything as last of my knowledge the cost of fine t a model can vary based on several factors and the amount competing resources for more accurate information okay do you have any information are you just making this up let's see if they know general knowledge available up to the last so I think that it's saying that it doesn't know okay it doesn't know so uh the idea here is I'm going to go clear the chat so we're basically starting over and let's see if we can add a data source and hopefully we can use Azure AI search as we do it we have created Azure a search separately um but let's see if we can go through this completely so we'll need a data source and we can do blob storage but I want to it says connect an existing resource or um create a new index so I'm going to create a new index notice it says the word index um and so I'm assuming that's going to use Azure search and we are going to go with blob storage well it' also be useful to connect with data in Azure studio so there's a lot of options we have here uh let's go over here and take a look what we have over for data um yeah and so this one so if we have Azure AI search then we'd have to connect create a new connection here and then this one would go to a storage account as well okay so there's a lot of ways we can connect data but again I want to focus on trying to do Azure AI search because I think that is the most interesting and I don't have one right now yeah so if we go ahead and we try to use blob storage yeah it says add Azure a search resource and open ey connection will be required to to index your data create a new Azure AI uh search resource so it's already suggesting that we would have to do that let me go down here again yeah so I guess we're going to have to create it anyway when I did this before I was able to create Azure AI search through the UI but I can't seem to remember how uh so we'll just manually go create one um so we'll go over to portal. azure.com and we'll go over to AI search before we create this I think we need blob storage but um we'll try anyway I'm going to call this uh AI rag for um because we basically that's what we're doing here we'll just say AI rag or like AI search Rag and I believe that this one here I don't think it matters but I think that this one this project here yeah it's West us okay let's go ahead and do West us and I'm going to change this down to the free tier as we don't need to make things super expensive here let's go hit hit next this is fine we'll go hit review create give it a moment here and we'll go and create our Azure AI search resource our deployment is complete let's go to that resource so from in here let's drop down search management the first thing we need is an index um I mean we want to have a data source so connect your data start here to import your data we'll go ahead and add an index um and I'm not exactly sure what we want for Fields here so I'm going to go back for a moment before we create an index I'm going to add a data source and and see if we can do that so hopefully it'll create one for us it won't but what we'll do is make a new tab here and I'm going to go over to Azure blob storage or just Azure Storage storage accounts here and we'll create a new one here and this one's going to be in our rag call this AI rag West us um I'm going to ignore these options here I just want to go with standard they they just started doing this where they have um AI Rag and some numbers here on the end they just started uh giving these options here I just kind of ignore them as they're just suggestions we'll go with low uh low locally redundant storage because I don't need more than that there are a bunch of options here which are interesting I don't know if we have to enable them to connect for um Azure are search but we'll go ahead and try this I'll give it a moment and while that's creating let's go prep this article so this article has information in it and um I just want this contents here so I'm going to copy this and I already have open here the Azure examples repo if you want to open this you just press period uh you should be working your own repo but I'm going to make a a new folder here I'm going to call this Rag and I'm going to make a new file here and this one is going to be um uh finetune pricing dot markdown we make it a markdown file I'm going to past this in here and so we have text I mean I don't even know we need anything else besides this but um just making sure that this is formatted away that makes sense so we have new price previous price H so I'm just wondering if it will understand this format because I'm looking at I can't really make sense of it so let's go back over to here and so previous price was this and then new price was that was the tokens new price so previous price was an hourly cost so here we're going to go and we'll just say previous price new price previous price new price now there are other ways that we could um prep this document but I'm just trying to keep it simple here today new price new price and uh yeah so you know maybe we'll just do a bit of formatting here basically making a markdown file I was not going to make a markdown file but now I've decided I'm going to so maybe the structure will help it out oops oh we're going to do three here models uh Azure open AI search um f tuning or this is azure open ey service fine tuning price change okay so we go here uh more information reasons for change okay and so now we kind of have a structured file that we can U bring in so I want to go back over to here um here and we'll go to our resource I'm assuming this is going to use blob sorage we're going to go over to our containers remember uh there's some new new icons over here which is interesting and I'm going to go ahead and just call this data we'll create that assuming that we're supposed to create it ahead of time like this not really sure and so I just want to upload this I'm going to have to download this file go ahead and download this if you're looking for this file look for the Azure examples repo it should for the most part be in place of where you want it to be and give me a moment I got to find the file there I found it um and so I'm going to go here and just drag the file and upload it and so hopefully that will um yeah it's blob block so it's clearly a blob file so hopefully we can then now add that here um we're going to have to go back because I just created that data source so we'll go ahead and hit add data source as your blob storage we'll just say data and I'm going to choose an existing connection and here we have our AI Rag and we're choosing data say select and so now we have an established connection there manage identity authentication if you enabled uh identity on your search you have the option to authenticate I mean I haven't so we should just be be able to leave that alone that's the container it's everything in the folder that's it let's go ahead and save that all right so now we have done that we're going to go back over to here and I imagine well we haven't done skill sets yet but I imagine we'll have to do an index just give me a moment all right uh so let's go ahead and create an index we will add an index and so this will just be um data I suppose and we need content here that we're going to search across we have an ID and I'm just going to call it content I'm not really creative with these names here so I'm just going to go ahead here call it content we have different fields here I mean basically it's a string I don't think there's anything else yeah it's just a string and so that's going to just contain our content I would think okay we'll click into that and yeah I'm just trying to think like how would that index our data like if I type in here and just say Azure uh if a query contains a search uh Target okay just give me a moment all right so I didn't get a clear answer but while uh researching I did find something interesting uh that I did not notice but there's this import data option I'm not saying we're going to use it right now but apparently it will do a lot of the work for us so here uh we have an existing data source actually shows up maybe we can use it because we do have the data here and maybe it can create that index for us so I'm going to go back here and uh because I'm not sure we have index and indexer so maybe what we should have done is created an indexer to then index our data and then put it in the data store yeah that's what it is so I think import data would just do the exact same thing but we'll go ahead and do this index data source uh there's a skill set so a skill set I believe is basically Transformers for data so we go over to here for a moment um and take a look at our skill set let's just take see what we have here yeah so we have skills all over the place and yeah I think that's what it is give me just a moment here yeah so that's exactly what it is a skill set is just a way for us to add additional processes before things get imported right now I don't really have a use case for this so um uh let's not that interesting for me but imagine that we had in our data store a bunch of uh PDFs then we could OCR that and that would kind of be actually interesting so maybe we'll try that after we get something working if we have time here but right now I'm just going to keep it nice and simple um so let's go back to our indexer here and we have a schedule so I guess I just want to run this once oh run okay that's the first option here that's perfect we have back size we have all these these numbers here whether we want to exclude information data to extract um I mean I just want the content but we'll content in metadata that's fine we have parsing mode which is fine this is just markdown so set to text to improve uh indexing performance on Plain text files I mean that's what it is it's a plain text file in a sense it is a markdown file but that's basically the same thing image action so ignore embedded images or files that's kind of interesting and we'll go ahead and save this okay so we have saved our indexer I want to go ahead and run this say yes only thing I'm wondering is like how would it know to map to the content field because here we never told it how to map um so that's something that's kind of interesting if this doesn't work we'll just do the import data that's totally fine as well but yeah I'm not sure how it would know what fields to map to did it run I mean it started cool so let's go back over to here oh was successful excellent let's click into it did we get any results execution history it says it's successful um nothing of Interest here that's telling us how it's working but let's go over to our home back into here into our indexes it says document count is zero so it says there's no data here and so yeah I'm not really confident on this so what I'm going to do I'm going to delete this index okay I go back and delete this index here because clearly there's a little bit more going on here that I'm not aware of delete this indexer yep and let's try the import data and see if it actually will set up everything for us so we'll go say import data and hold on there's also import and vectorized data that sounds even better let's do this so we have uh Azure blob storage Y and I'm going to choose AAG and I'm going to choose data and it's everything in there I don't think we need to authenticate so we'll go next vectorize your data as your open AI so yeah we need something that's going to do the vectorization we did this in a um a notebook before where we vectorized the data so open AI is totally fine so like that's what we would utilize here we have Azure open AI search yeah so we actually want to do East because that's where this is oh no no no we're over here actually no deployments available when with an embedding model okay so I mean I guess it doesn't really matter what we use to to do it because it's just going to get the data in there and then after that doesn't really matter but if we go over to here no deployment model available so so something has to actually do the uh embedding and this one's in open AI Studio 20 2134 is that what it is 21 213 so I have to figure out what I keep putting random numbers so it doesn't help me much but I'm going to go back to the hub and so the one that we're looking at here that's in West US is an Azure Studio Hub but it's 1 two 3 4 but the question is which one which open a is it using so we go into here and it will have connected resources connections and here we have one 2 3 49 huh okay so maybe these are just isolate ones that are deployed they have nothing to do with Azure AI studio so let's go over to open Ai and here yeah now we have two we have West and East so we' been doing everything in West I'm going to use this one which is the 2113 we have 2 21 1 3 and say it has no active deployment so we're going to go over to a model deployment and I'm going to manage deployments it's going to open up us up an Azure open AI um Studio because you can't do deployments the old way anymore which is fine and so it's saying I want something deployed here so that we can um uh vectorize that data I'm going to assume that we can use gp4 I also kind of wonder if we could use gp4 mini but I think it takes time for that to come back so we don't want to use that so I'm going to use um uh I'm trying to decide here because we could probably use GPT 35 turbo but I'm going to go ahead and use GPT 40 we'll go ahead and deploy this and we'll see if this will do what we want okay give it a moment here to load and yeah I'll go with global standard I think we found out that was probably the best one that we could possibly deploy and we'll wait for that deployment to become available seems like it's like instantaneous so that's really good I'm going to drop this down again give this a refresh oh with the available embedding model so maybe this deployment is actually useless now that I think about it because it has to be an embedding model right um so maybe they'll indicate yeah with embedding so we have text embedding three large Tex edding small now some regions don't have access to these so hopefully these ones will Loy um I'm not sure what the difference between small and so small are the latest models offer better whatever let's go with small cuz we have a small amount of data hopefully that just works that'd be really nice this model is not available for Azure openi resource cancel let's go back of course they would make it difficult let's try this deploy yeah so it's really weird that they do that and they don't make it really easy for us is there anything else I can do embeddings not that I know of there's also Ada let's try Ada but cannot be fine tuned okay maybe we'll avoid this one and if that's the case let's just switch over to our other Studio which is in Sweden and we know that the Sweden one for sure for sure uh will we got a lot here I think it's this one one two no that's not it oh East okay yeah yeah these are ones these are ones that are just individually deployed they're not necessarily part of a studio but I think we I think that this one we'll have embedding so let's try the small embedding here see if that works so it's really interesting where some things you're forced to use open Ai and the other ones uh you'll want to use AI uh Studio we'll give this a moment to think it looks like it's going to do it but it's uh having a hard time here today all right so we have uh standards so I guess that's what we're going with here today and so we'll uh deploy that and it looks like it's instantaneous it's deployment which is nice not something I'm used to with Azure but we'll go here and choose the small again I don't know a huge difference between the large and small model but I'm assuming that small is good enough for our use case if it's not we're going to find out uh will inure additional cost to my account yes of course everything costs money if you're afraid of using it you can just watch along but it's up to you there are no images in here so we don't have to worry about that enrich your day with AI skills so that's something that we could do during the vectorization it's interesting that they show it at this step um but I'm not interested in doing that right now so go ahead and hit next um oh yeah we're doing this in the rag so I I for some reason I thought we were in the other interface I'm going to set this to once and this is going to generate an index an indexer a data source uh and a skill set so all those things we could have configured for whatever reason I didn't know how to do the indexer we'll go ahead and create it but now I'm starting to think about this is very similar to U adab blue um so the similar components and I mean it looks like it's done I'm not sure yeah we're just waiting for it to create so I'm going to oh okay so let's go ahead and hit start searching that was easier than I thought let's type in open AI open AI here and we're getting back Vector data so there's only one document um this probably be more interesting if we had multiple documents here but uh again I'm just going that I do not know how to do the import and um that's where we could run into issues let's take a look and see what it did so in the indexes if we go to fields we have text Vector so that's the text Vector data we have chunk so I believe it stores it chunks and then both stores the text Vector data we have a title which I don't remember coding we have the metadata maybe the title of the document so that if we need to find the document we can look it up um let's go over to the indexers and see what they did for this so we go over it settings I wonder if it's pre-filled um yes that looks fine but how did it know how to map the fields so here we have mapping Fields mhm so yeah I I don't really know maybe it's based on convention like if you have vectorized data will place in the correct location but I'm not sure how it knows to do that but at least it works okay so now that we have our data the idea is that we can um uh go over and finish connecting our resources um in Azure AI Studio Hub so let's go back over to wherever we were I think it was let's go back over to our Hub this one is where West us so we're back in West us we're going to go back to chat and now let's see if we can connect Azure AI um search we're going to add our data so we'll create or select a project oh we're not in a project right now let's make sure we're in a project first there we go and then we'll go over to chat and from here we'll add our data and we'll add a data source and we'll say Azure AI search we're going to go ahead and hit next um we'll connect to Azure AI search and we have different ways of connecting I remember having a a lot of difficulty connecting um so if we can use API key I'm totally fine with that so here it says add a connection your Hub will be granted access to this resource anyone with this will be whatever so let's go ahead and add a connection and we'll choose this index here and of course we would need a um a means to doing this so this is azure open ey embeding model will be deployed if not already adding the vector data so here I'm I'm not sure if we should do this because if we have embedded with a very specific model I would think that we would want to um use the same one and so I'm kind of concerned about that and so because of that I'm not going to proceed forward here I think that's a a mistake and let's go back over to our Hub and launch a hub that's in uh East usest unless we already have one and we don't have one so I'm going to create a new Hub and I'm going to just put this make a new resource or we'll put it in our rag one because everything's being done here and so we'll want a new Azure opening I search service and here it can connect to our Azure I search and actually let's do that because we need to do it anyway and that might save us some trouble we go ahead and hit next and create anytime that Azure is going to do the work for us let it do it because it can be very difficult to connect these things and so we'll just wait for this to set up okay all right so that was created for us and um I mean if it's connected that way that's definitely easier for us let's go over to connections and see yep we can see the connection is established and use the API key type so that's exactly what we would have done um it says cognitive search because that's what a Azure AI search used to be called let's go over to um to projects we don't have one yet so we'll just make a new project I don't care what it's called and we'll just give it a moment here to create and we now have our project so on the left hand side I'm going to go to chat and oh we need a deployment so let's go ahead and create a deployment I'm going to work again with uh we'll go to model catalog and I want to deploy GPT 35 turbo again intentionally because we know that it's out of date and here we will establish a connection I assume that's the only one we can connect here and we'll stick with standard we'll go ahead and deploy that that is now deployed we'll go over to chat and it doesn't seem to be aware of the deployment let's give this a refresh here sometimes needs to propagate so be very patient there we go we'll go ahead and add our data so we already have um a connection so I'm just wondering how we can do that so we'll say add a data source we'll say aure AI search we'll hit next and I mean we already have an established connection so I'm not sure why we have to click through this to find out so what I'm going to do I just I want to see if it's already connected I'm just going to say uh let's go take a look at our document um and so we'll say uh what is the price change for babage for fine tuning let's see if it could pull out there um it's an open AI model can you connect via Azure AI search and check okay so that didn't help it um maybe we just go a question and and say like here it's uh prob it had like a date in here I just realized there's no date in here uh we say what are the pricing changes to Azure open Azure open AI service for fine-tuning and I'm trying to get it so it doesn't seem to know okay so we do have a connection and I would have thought that we could just add that connection not have to go through this whole process but let's go ahead and do this anyway so we'll say Azure AI search and we'll go next and we will choose Azure AI search we'll choose this Vector here I'm not sure why it's saying that so that's kind of annoying but now we can select an embedding model that makes sense and here it's still trying to choose text embedding add O2 okay so maybe here we need to deploy because it will pick one by default but I'm going to go ahead here and just choose that embedding model the um the small okay and let's go ahead and deploy that that's another thing is like how would have that chatbot used that data source if there's no embedding model deployed it probably wouldn't be able to all right so we'll give this a moment here all right so we'll go ahead and deploy this model I'm kind of wondering why that index is not working and we are in eastus so I wonder if we'll have to create another Azure AI search connection but in the correct region I try to keep everything in the same region but uh you know not everything works as expected so go ahead and we'll try this again so we say Azure AI search is very finicky to get the stuff working and no issues with the index this time around but maybe the reason why is because we actually have a um an index so now we're going to get the index settings here next and so let's go back here as your open embedding model text embedding at a O2 will be deployed if not already adding to your account and so I just keep thinking like is that going to work for us because we did not use that as our our um embedding models because these embedding model should work differently right and that's a little bit frustrating because um I wish I had known that up front earlier but I guess we'll find out it'll either work or it won't work right so here we have uh some configuration options how we can search so semantic search seems pretty good there's also Vector keyword search um so there's just different ways that we can go about searching and I'm not saying I'm familiar with all these methods um I think that we saw these when we we were running the notebook and using Azure AI search programmatically and semantic search would probably give us the most likely best results but we're going to stick with Vector keyword as it's suggested and let's see if we can find out um what are the pricing changes uh for Azure open AI search Azure open AI uh services for fine tuning okay and let's see if it can do this like would it be smart enough to know to reach out there oh look at that okay and so it's giving us a reference okay so it has citation it's showing us the changes here uh can you come uh show me can you make me a table of old and new prices price changes for the uh let's see if we can do that I'm not sure if we can do tables here oh did okay great and there you go so there it's referencing it and so that works that is really cool one other thing that I think that would be really cool to try if we can make it work is to use a skill set to OCR a PDF document um that is a huge challenge for a lot of rag systems is you have to have some way to unstructed IFS is definitely one that can be a challenge now if you use a powered AI assistance like TBT you'll take for granted how easy it is to uh drag those over but um you know we'll we'll see what's going on there anyway so um yep hard case so let's see how we can do this um I'm going to go back over to um our AI search here and what I want to do is I want to because I guess we'd want to have another yeah let's go back over I know I'm talking over the place but let's go over to our data storage um our storage account for our our Rag and I'm going to make another container and this one's going to be called PDFs Okay so PDFs and the idea is that I want to have some kind of uh PDF information it'd be nice if that PDF information was um a a image or graphic um a graphic PDF where uh it's very hard to do that so I think what I'd have to do I I could scan an image in I'm just trying to think how I could do that so maybe what I'll do is I'll find an article here in your Azure AI Services blog and what I can do is print it out and then take a photo of it and then turn it into a PDF uploaded to the Azure examples repo so you can use it as well and then we'll try to utilize that so let me go do that I'm just going to go pick out a couple articles here um and I'll be back in just a moment all right so I've created a PDF and I've purposely made it really bad um I'm trying to be very careful uh because um Adobe or acrobat really likes to OCR things and I want these to be images right I want these to be a little bit awful I want these to be images because I want our skill set to do the OCR and not Adobe Acrobat um but let's go ahead and see if we can uh get that to work as expected so I'm going to go over to um our storage account into our PDFs and we only have one PDF here which is fine so I can just go ahead and upload that here okay so I believe it's on my desktop so I just need to go and grab it from here just give me a moment to find it um I called it GPT gp4 and we'll drag that on over there and we'll go ahead and upload that document right so that is now uploading so we have GPT 40 PDF that looks great okay all right so um that is now uploaded here and um the next step is to import that data so we're going to go over to um our Azure AI search and we'll go back to overview because this tool up here import vectorize was super useful and surprisingly using a different um embedding model still gave us results but I would imagine that when you are uh converting Vector uh Vector data you should probably use the same embedding model because I can't imagine they work all the same way over here to Azure blob storage we're going to now choose uh we'll choose this one and in this case it will be the PDF's directory we're going to go hit next and we are going to I guess it's the other one that has the yeah small embedding three small of course it costs money we know this we'll hit next we are not vored in theages we're going to go next and oh where's our skill set oh enrich your data with AI skills so extract text from images that's exactly what we're doing here today um and select a multi-service account no accounts found in the same region as a search service what what does that mean select a multi-arch service account I've never seen that as an option give me a just a moment okay oh maybe it's just AI Services okay that's fine let's go ahead and do that I mean I thought we already had that but that's totally fine I think it's like AZ Services where it has the unified API but um yeah that's exactly what it is okay that's fine so we'll put that in rag uh yeah r e us we'll just say um Azure AI services for rag not going to type it correctly I do not care here we're going to go ahead and do review create yeah sure we'll do this and review create and I guess the reason why is that it needs some way of accessing OCR and I guess there isn't already one there it's just the wording is kind of weird here they should have just called it um AI Services API and that would have made a whole lot more sense so just give that a moment to deploy that was quick let's go back over to here we're going to give this a refresh and oh dear what region is this in is this in West us this is in West us so my mistake um just because I'm confused because we have something East us and we're doing something cross region but I'm going to go ahead and create a new service as best you can try to keep things in the same region so there's not additional weird cost so we'll try this again AI rag eastus AI search uh R East not even trying to type it correctly just getting it in there go ahead we'll hit next everything seems fine review create and this time we'll have one in the correct region okay so that is now deploy we'll go over to here and we'll refresh and H did I make another one in East US yes I did sorry I'm so sorry I keep forgetting it's because I'm hungry I haven't had lunch yet here okay this time this time I'm going to make it in the right region it's not like it hurts anything making all these is not costing me anything yet but uh we'll go ahead and say West us okay pricing tier Azure AI search West us feel sorry for the people that are watching me making the same thing again wrong wrong wrong okay so we'll create this one shouldn't take too long so give it a moment and yep we'll wait here a moment so that Resource Group is now ready we're going to go over here and give it a refresh there we go we're acknowledging yes and so it's going to use the underlying OCR service how well it's going to perform on my documents I'm not sure but I expect it to work um so here are all of our options we'll go ahead and create this there we go and it's going to create the skill set so you know not the most interesting way to see how skill sets work but I mean we are technically using a skill set um but I would imagine that if we were setting this up manually then we could choose from a bunch of other one so start searching let's go ahead and try this out and make sure it works so what was in that document I already forgot uh this one has about um G uh gp4 fine-tuning so I'm just reading here oops wrong wrong thing we are excited to announce fine tuning capabilities for public preview fine tuning allows how much does gp4 mini fine tuning cost let's try this that's that's new that's like literally a few days ago how much does gp4 o mini fly tuning cost I mean that's a lot of words in here but we'll try it anyway I mean it's returning back data maybe just a single keyword might help here so let's just say um fine tuning I'm just matching it based on the document here I mean it's retrieving the document so I think the way it's it's going Vector data because the data is vectorized right so the way we're going to find out this this works really well is by testing it over here now we have this connected here but does that mean it's connected to the PDS or data so I'm going to try to ask the question over here and see what happens if it can site from that other document the one that we had OCR and so we'll expand this so this is coming from the the wrong one and so I think what we need to do let's go to advance settings here and I mean like I don't know if we can add multiple data sources so maybe what's important is that everything is in the same index for this to work because we only have a single index here I'm not sure if that's a limitation here but let's go ahead and remove this and I'm going to add a new data source next here uh great naming 5554 okay so we go here 5554 so this is the PDF one and I just ignored that error because I just obviously it worked before and we'll go next create and we'll set create and so we'll leave it on the vector keyword search it seems fine on that let's go ahead and paste in that question from earlier how much does gp4 mini fine-tuning cost fine tuning cost probably would help if I spelt it correctly here find tuning cost and let's see if it can pull out citations from that document and we have a reference and yes so it's getting it from there can you can you uh make it a table and let's see if it can do that for us there we go and that is pretty close so not perfect but of course our data let we have 03 and then oh no it's there okay it's just the way it visualized it okay so we have a simple one there and just it displayed it differently and so it actually did a better job than what we actually had in the document uh but yeah I mean like I was hoping that we could look a little bit more at the skill sets um so you can I mean you understand what it does it's just an add added filter um filter there but um I think if we wanted to have the flexibility to um actually do something with it we would have to um is it our indexer is it our indexer where we do that or is it our data source it's not in here so if we go into this I'm just trying to see where we added that um that skill set because it obviously did it for us right maybe it's when we're creating an index no it it have to be the indexer because yeah because at this stage it must be here you know we do this 554 allow skill sket to Red dat well anyway I don't remember where it is I'm I'm kind of hungry here but my point is is that we achieved what we wanted to do which was to utilize um uh rag for for uh using a skill set and also just generally fetching from a document but again it's really tricky to get that uh add that that search Service setup so if you're having difficulties with it that's totally fine I'm going to drag this over into our rag document here and I'm just going to go ahead and add docs for Azure AI search Rag there we go so now you have those available for when you want to do that and I'm going to go ahead here and just um uh stop this or sorry we'll do some cleanup and luckily we have that AI rag um Resource Group so we'll go into here and we have a bunch of junk in here yeah a bunch of stuff and we'll go ahead and delete that and so hopefully that successfully deletes but I will see you in the next one okay ciao let's take a look here at natural language processing also known as NLP and this is a machine learning technique that can understand the context of a corpus a corpus is a body of related text um so NLP enables you to analyze and interpret texts within documents emails messages interpret or contextualize spoken texts like or tokens like sentiment analysis it can synthesize speech automatically translate spoken or written phrases and sentences between languages interpret spoken or written commands and determine appropriate actions something that's really important when we're talking about llms um and one that existed prior that got rid of it in 2023 was the Cortana virtual assistant um and it would help you with Bing search and perform other tasks I guess kind of like uh Siri or um Alexa but um yeah they retired it because now there is basically AI agents so the old term was virtual assistants these were um uh basically big IFL statements using NLP to complete tasks and now we have llms which we call AI agents which have more agency more intelligence around them that use NLP what are the NLP offerings for Azure well we have text text analytics so this has sentiment analysis to find out what customers think find topic relevant phrases using uh key phrase extraction identify the language of text with the language detection detect uh and categorize entities in your text with name and recognition we have um language understanding um I guess you could call it Lewis like the name we have here natural language processing service and enables you to understand human language in your own apps websites chat Bots iot devices and more Lewis is more for those virtual assistant the old way of building um these kind of if else uh NLP agents I don't uh not agents but Bots I don't personally like that anymore I just find them very um uh limited but they're great for let's say websites where you need a a chat bot and llms are going to be too expensive we have Q&A that we can use NLP for as a service so this is where we have custom question answering allowing for the creation of custom question answering models from your content or you can have a pre-built uh question and answering model again these are for Bots um for your platform we have speech so this is where we can transcribe audible speech into readable searchable text so there is um the NLP offering and within text Analytics there's a lot that we can do with it you'll find out when we get into the labs of text analytics okay hey this is Andrew Brown in this video we're going to uh take a look at text analysis so I did this previously for the um AI 900 and uh I need to do it again um whether you're taking the AI 900 the or the AI 102 they're both relevant um so um again this was three years ago so I'm hoping that this thing still works and we can walk through it but um yeah let's give it a go so you should have an AI managed API compute on the lowest possible cost here I'm going to go ahead and start this up and once that's started we'll open up the Jupiter lab notebook we'll Port this over and see if it still works I believe that it's still called this um but yeah we'll figure it out okay all right that is now running let's go ahead and open up Jupiter lab and so I think that there is a um a new uh it like a new P it might be the same package just but renamed but I believe it's called Azure AI text analytics why the naming I I don't know but um what we can do is try to give this a go um maybe the code is very similar so if we take a look here we have text analytics client um this is obviously been changed I think that they've made a generic one and that's probably one of the reasons for the changes but for the most part it looks the same and I mean obviously this is still cogni microsoft.com so you know that that's going to be the same there but um let's go back over to here to our jupyter notebook I'm just going to uh sure hit build and um I'm just going to go up to AI Okay so we've been working with this so you should be familiar with um this environment if you're not watch the setup video in here I'm going to make a new folder this will be um text analytics and so I'm going to try to bring over this stuff now of course if you want to just copy and paste this you can get it from the a examples because you'll have this it'll be uploaded here um but you know do your best to follow along and the existing one is here in the uh the free AI 900 uh here okay so um I'm going to go ahead and give this a go so here it's doing system executable it think we have to do that we just do pip install there might have been a reason why I did it this way I don't remember why but I'm going to go ahead and go back to here maybe I just didn't know better at the time but we are going to go into our text analytics folder and we're going to make a new notebook called text analytics we're going to choose just the SDK keep it nice and simple um and I want to rename this as text analytics okay we're going to go ahead and uh paste in just that part there and put that presented that's that magic symbol allows us to uh install things and so this one is called Azure AI analytics just going to grab that name here just in case you're looking for this link I'm not sure why you want it but if you do I'm going go ahead and add this drag it over the top here whoops above above there we go and save resources here I'll just paste that on in there okay so we'll go ahead and run that first we'll wait for that to pass good and I think for the most part it's going to be the same what's going to be a little bit different is that this one here yeah it's going to have the Azure key credentials as the key difference here so I'll paste this in here sometimes when it says this you need to restart the kernel to use these packages sometimes you do have to restart the kernel so I'm just going to do that right now um restarting the kernel can clear out variables I'm not sure how we know that it's restarted somewhere it would indicate that um but the next thing is we want to import uh these values I'm going to take a look at what I have here so yeah very similar um and then the next thing is going to be the key and the end point so I'm just going to bring on those on over because those are going to still stay the same um and we'll go back over to here so this is going to be this so we'll go over to here and bring that on as the next part and I'm just going to take this part out this is going to be endpoint and here for credentials we'll say my key my endpoint now remember that we have the Azure AI service so we should be able to tap into that we could individually create it that's how I I did it before is under the AI Azure AI Services I would have just gone under wherever that category was um text analysis and we would have um uh just added it there but we have this so we can go into Azure AI services and get our single key and we'll go back over to here and we'll replace this here and so now we need the appropriate endpoint so which one is it go here um I mean this is text analysis so I would think it' be document intelligence could it be computer vision uh I'm not sure so let me go back here let me go here and take a look I'm not sure just give me a moment uh so I looked it up and it's under language so that is the end point that we're using so we going to go ahead and copy that one and we're going to go back over here um if you're expecting build failures I don't care we'll ignore that and I'm going to go ahead and paste this in here there we go so now I have my key and my endpoint and we'll go and run this next part and it doesn't like something so say name Azure key credential is not defined so oh you know I forgot to run this then will run this then we'll run this so now we have no problem so my prediction is that nothing has changed and we can just use the stuff that we had here before looks like I had some uh movie reviews in here so if we have those we should bring them back here and it looks like we have some movie reviews I don't remember how we got this but this is clearly for Star Trek so I I have a series of movie reviews here so um it' be good for us to download so I'm going to go ahead and hit period here and I just want to then uh download these in Block to save me some time so I'm going to go ahead and just select them all here and oh maybe we just download the folder and we'll say download and you know you just download it to wherever you want to download it to I'm just going to download this to my desktop here GitHub can't open this folder because it contains this some files fair enough so if that happens I just have to create a folder within a folder so on my desktop I'm just creating a new folder I'm just going to call this um AI uh files assets and I'm going to go ahead and select that folder and we'll say view Sure Save changes I just wanted to download the files however it's going to do that and they are downloaded excellent so I'm going to go back over to here and I want to bring those files in there so I'm just going to hit that upload button and bring them in so I'm just going to make a new folder here I call this assets I'm just going to follow the same structure because I clearly had more folders there and we might want to do those things movie reviews okay and so we're going to bring those in here just a moment I say just a moment I mean like I'm going to hit the upload button and bring them in that way okay there we go those are all now uploaded keeping the same structure um curious about these ones but I guess those are for um uh different ones here we have a bunch of different uh notebooks here so I'm going to go back over to um to here and actually I probably just open now that I have it open up here I can do that and just again remember the way I opened this was period when I was in that repo if we go over to here I just want to take a look so we now need to get the path that means I probably need to import that right yes um so I'm going to go back up to here it's B wonky but I'm going to just place it right here and we're just going to run that I'm going to go here and grab OS path join there's probably a newer way to join paths because um I know there is but I'm not going to worry about that so that is now joined and so we have some code here I'm going to go ahead and copy that so we're saying we have a reviews and we're going to list the directory so list the contents of this directory iterate through it open each of those files read its contents and then um we are going to create a new um a dictionary and then we're going to append that so we're basically creating a an array of dictionaries from there we're going to get the length of the reviews so we can determine the range to make a for Loop and then we're going to print out so that we can confirm um that we have our reviews so that's the first step there and probably when I originally did this I probably wrote this all all by hand so um hopefully you don't mind that I'm not recoding this from scratch but um I don't think it's necessary so we have client. key phrases where we can extract out key phrases we'll go over to our next part oh so we have a few things right so we can extract out key phrases and then we're going to print out those key phrases then we have sentiment and then we're going to print out the sentiment so looks like we got a couple things that we can do here and we'll go ahead and add that and we'll grab this one I could leave up the older video If people wanted to see exactly how I coded it I don't think it'd be that interesting um this one we already had so I'll go back over here and we'll grab sentiment and hopefully it just works we might have to modify it we'll we'll find out here in just a moment but I'm thinking it was just a rename and a consolidation of API end points okay so let's go ahead and run this and see what happens so here it's Consolidated them and we have uh some reviews great then we'll go here and we will see if we can capture key phrases so it's saying doesn't know what client is it probably has to do with this so I'm going to go ahead and change this over to be this and we'll change that excellent we'll go back down here execute this it's saying has no turb key phrases okay great so clearly the API has changed a bit not a big deal we'll go over to here and see what's what so just give me a moment to find what has changed so um I was just trying to find where we can do that but I'm just also noticing that there's a lot that we can do this Library I don't remember it being able to do this much but it looks like it can do all of these things that's quite a few things and so I'm going to go down here to the bottom and we'll go to our examples which is extract ke phases and we'll see what has changed so seems like it's supposed to jump to exact C phase it's not doing that so I'm just going to search for it and so here we have an example um so here it's saying okay here's the Articles and they've named it extract key phrases so the wording is changed a little bit I mean they're enumerating another way I I have a feeling that we can probably just use what we have here um but I'm going to go back over to ours where we have key phrases and I'm going to go ahead and write extract key phrases so we'll try this instead extract key phrases extract key phrases we'll run this and see what happens oh sorry you know what this is the wrong environment let's go over to Here There we go we'll run that and it's extracted out so it clearly worked now the question is the the return different we'll run this we'll find out in just a moment and so it looks like it's changed a bit so this syntax syntax has changed um but it clearly is returning stuff it's saying here um extract keyphrase results key phrases so here it says results and then we have do documents um so I'm not sure what it wants here let's go back over to here just give me a second so I'm thinking what's changed here is that it just doesn't have documents anymore so let's go ahead and take that out and run it um so here it's saying results i1 key phrases document object has no attribute called key phrases the service was enable to process the document okay so maybe a way we can debug this to fix this I'm just going to calb this out for now and so what I want to do is I just want to take a look and just say print reviews we obviously know that's going to work right so run that so we have ID review text oh hold on but that's not our results so I want to go ahead and say print results there we go so now if I do zero can I do this let's see if we can do that will that work we can and so from here we are seeing um that we have an ID so we can go here and say ID right and then here we can say he phrases right okay so if that's the case let's go back here there's nothing WR my code I just like to keep it around here there's another way we can enumerate it but this is just the way that I did it there is an enumerate um uh thing in Python but because we know there's exactly 10 it's just easy to do it like this so here we have um the reviews and we are iterating through them we're minusing one because the index will start at zero right and so the key difference here is we're just doing this like that there we go and so that should get us our key phrases um did I write it wrong copy this paste this here and well actually you know what the ID here is is a little bit different so maybe I'll I'll switch this to enumerate just give me a moment okay so I went back to this code example and notice here it has this enumeration so here we could say enumerate the results and I'm going to do doc do keyphrases so we'll try that and see if this is a little bit better okay um so do this and then we can print the idx okay I'm just going to comment this out for just a second because I want to see what the results are go ahead and try this out results sorry okay so now we're starting to get somewhere okay great um so we have that and then we actually have the document now we could go here and just say like document um ID and that might look oops a little bit different here oh sorry doc sorry doc okay and um yeah it's up to you like whether you want like that or this I'm going to go back to idx because that's actually how originally was working and so then here we want to extract out our key phrases so this one's actually just going to be even simplified here so it just be doc. keyphrases going based on that example that we saw okay and we'll try this and there we go so here it's extracting out the key phrases for each of these movie reviews so that's the first thing that we are able uh to do um and it has a problem when it gets to here for some reason document text is empty we'll go into here and it is empty so um maybe that was intentional let's go ahead and take a look here it is so you know that's not the best but at least we can see that there is an error uh if that happens and so we might want some error handling on that so I wouldn't call this a failure if you want to fix you just fill that in I'm not going to worry about that error I don't care about it um so the next thing we want to do is maybe sentiment analysis so let me take a look here and see how that has changed because it probably has a different name it's probably something like analyze sentiment we'll go here and analyze oh I was right okay great so now we have antal analyze sentiment so I'll just switch that out here this is using that range so we can just update this code to be a little bit nicer um this is going to be kind of annoying so I'm just going to put any kind of review in here so I really enjoyed the uh Red Dwarf uh series and I wish this movie had more movie had more of that okay so we'll save that and just to make our lives easier go all the way back at the top here um because we're going to have to rerun some of these things not this one I'm just going to reset everything here and we're just going to restart clear all the outputs so you can see what we're doing here there we go so we'll run this and then we'll go down and run the next one once this one's done run that then run this then run this and attach our our ourself there um and then we need to assemble our documents we'll go ahead and do that and here it's having a little bit of an issue I'm not sure as to why all of a sudden it doesn't work um I'll try running this again I just don't trust it maybe it's out of order see that says seven here seven and we'll try that again file name and not sure why this is having a problem so we'll run it from the I got to clear it out again yes I know I'm being very silly here but we'll clear it all the way out and we'll just be more mindful here and just go a little bit slower okay there's a few kind of text analysis things that we'd like to do here not just just key phrases so that looks like that's done we'll click this one good we'll click this one great click that one we'll do that one and we'll try this and now all of a sudden this is not working anymore so assets movie movie reviews is a directory yeah we know that so um okay uh right so let's go ahead and just start printing some stuff out here to say uh file path I do this and it's weird because it was working perfectly fine and then all of a sudden it's decided that it doesn't want to work anymore so go ahead and do this and it says missing one required positional argument file oh fair enough yeah yeah yeah yeah file path but right now I just want to um print out the file path so that we can see what's going on here because clearly something is a miss so look at that we have um ah so it's printing out this file which we do not want so that is clearly a file because it has a checkpoint and that's what it's complaining about so we need to um skip that file I suppose and I'm going to use chat GPT here today because I just want my life to be easy python is not my primary language so I know what I would want to do to check for that but I'm just going to have them write the python for me so um you know I have this this code I need help with this code please wait for further instructions okay so go here this is the file this is the folder I want to ignore the um IP y andb checkpoints or sorry I said I only I want to ignore all files that are not named review xtxt format okay let's see if it understands what I'm trying to say um yep that will work so go ahead and copy this that's all I really wanted and so we'll go back over to here and we paste that on in here as such this yeah this is that so we'll go ahead and do this I'll just do two spaces so now we can just take this out of here there we go and we'll run that great excellent excellent um might as well we'll just run uh key frame phase extraction again just making sure that is all in good working order so that is good let's go down here and figure out and uh analyze sentiment so we'll go ahead and hit run here and it's return back information so looks very similar um this one has sentiment warning statistics a bunch of additional information um this one has a score so that's probably what we're interested in but it look to be a little bit more information than previous because here I'm seeing positive neutral negative it's not just a single score and interesting so um I can't remember if it was Azure it ofs but at one point there was ability to check just a simple score or a more complex score I'm wondering if that is what's happening here because here we have sentiment analysis no it looks like it's checking for everything and I mean that's totally fine uh we'll just modify the code for this to work so we'll look at one of the examples here so we have um the sentence here and so this I want to iterate through so I'm going to go back to our our last example just going to collapse this here this one's a little bit messy and so I'm going to grab this as our example we'll go all the way down to the ground and we'll hit enter here we'll paste this in so we're going to enumerate enumerate over our results like the last one and this one here we have an ID then we have a sentiment so I'm going to go here and I want to let's say print out that so we need the we need that there and I'll just say uh sentiment sentiment and from there we will place this in here so that will be my first little attempt here to see if this works don't think we need spaces in between there yeah we we'll do that anyway and I'll just take out this old one because this one is no longer relevant one two 3 4 that's fine doesn't matter so this is kind of working as expected uh we might not need this additional one I'll just STI that out out that's a little bit better um I might just do this and just say like just so I can see a little bit better where we are it's a little bit hard to uh view that there we go um and do we even need this seems like it's putting the brakes in pretty well here yeah that's that's a lot nicer I'm just going to maybe I'm just going to put this on the other side I know I'm being really finicky here but it might just be a bit nicer if we can see what we're doing there we go and so I just want to um print out some of the other information so we have sentiment we might also want to have the original sentence this say sentences uh maybe I'm just going to yeah we'll print it out I guess I just seems like it might be a little bit a bit of work to get at it because it's having multiple sentences we'll say sentences sentences and I'm going to hope that I can just do zero like this and say text hopefully that will just work that'd be really nice it does excellent there could be multiple sentences there but we're just going to focus on uh the first one and then we have the confidence scores so go ahead here and just say scores so that will be Doc confidence scores um we'll say positive and see if that works so that did not work as anticipated it says here has no tribute called positive could we do this instead maybe does that work no it does not what if we just printed out out and see what we get okay so it clearly is returning a dictionary so I I could have swore that we could do this why can't we do that okay so we can okay so score positive and then we can do this for neutral new trol neutral and then we'll go here negative negative all right so we'll go ahead and print that out and so now we are getting a lot more information so that's very cool um so we did uh sentiment analysis uh uh key phrases we can also um do recognize identities let's go back over to here just see what else we have we have got language detection entity link linking personally identifiable information that one might be interesting to do I'm just trying to decide if that's really hard I don't think it's hard to do so let's go ahead and try that one out so I'm going to go and copy this and go down so this one here it appears we do this so let's go ahead and give this a go so I'm going to do that and usually we do what is it documents equals reviews like this reviews and then we'll have our results here and then I'm just going to go here and say print results let's see if we can do that oh this one's just called client I believe client uh didn't like that okay too many records Max five are permitted okay so can only take five at a time um let's go ask tobt I have I have an array in Python I only want the first five items okay that's easy so go back over to here reviews reviews first five and we'll do this and we'll try this there we go so we get some kind of structure back we're going to probably want to enumerate through it so I'm going to grab this per usual CU that looks pretty good to me and we'll paste it down here and we'll say print um and what kind of information do we have so we have entities so we'll do that say entities it seems like we'll have to iterate through entities so I'm going to go up to our key phrase example because that that looks like it's more like what we're doing here right and we will grab entities here see entity entity and so we have text okay so let's see what we get here so we have Ronald Moore cowriter Enterprise crew lender Nemo so things that it's identifying and then the other thing is like whether that information is um sensitive I suppose so we go up here and take a look so we have Ronald deore ah the entities is within that review right and then from there it has a confidence score okay identity confidence score so I'm wondering if we can just do that see if that works good I was wondering if like in these category subcat ah so we have the category or subcategory so that might be interesting so I'm going to go here and just say entity. category entity. subcategory if I spelled that right that should just work we have R deor person none type organization the Enterprise I mean that is a rental company but um there it's actually talking about a car company and so we're getting uh some information in here so yeah hopefully that is interesting to you we could spend all day doing this you can see it's not very hard to figure out once you start get getting the pattern down here um kind of interested in in uh text summarization so you have extractive and abstractive one generates from one the other one is that it's kind of interesting because this feels more like generative AI um or llms and I'm wondering if they're kind of working that stuff into here uh so I'm just curious what that looks like here so yeah it looks like it would take a lot of text and then summarize it so I'm very tempted to try these out so I think that we should do that I'm going to make that a separate video um so I'm just going to keep this workspace running because that video is going to follow this one right after this one so if you want you can stop I'm going to keep my running I'm going to leave this open and I'll see you in the next video okay ciao hey this is Andrew we are back and I just said um I was keep this running so just start this back up um and we are over here and what I want to do is I just want to go ahead and create a new one because this is actually really says text analytics but this is really the language API so I'm really going to rename this it's going to confuse people here but I'm going to rename this to language okay um language because that's actually what we're doing and I really have a feeling I spelled language wrong I spell it wrong every time I write it language language and it is g u a g e okay so it's u a u e um so hopefully that's not going to upset people too much and I do apologize uh if that is confusing anyway uh so what I want to do is go into here and this one's actually doing a few different things but I can just leave that and call that text analysis I'm going to make a new note book here and this one's going to be extraction so I'm going to go over to here and select that I'm going to rename this as extraction I'm going to go over here because I don't really want to run more than one kernel um so I mean they're all using the same kernel so I don't think that's an issue okay great so I want to go into here and get this one going okay so they have two examples they have this one I'm just going to go and grab these in the top here and just say resources we have this one which is extraction summary yeah we'll do that one and then we'll put the other common in there so let's take a look and see what we can figure out so this is the first stuff we want to work with so I'll go ahead and do that don't know why we need the OS I don't feel like we need it but that's fine um before we do any of this we actually need to install this so I'll go here and drag this above there and we'll install that run that and I'll need my keys as per usual okay I'm just going to collapse that as that is working through that and we'll bring in our keys um and then we have our Imports so while that is working I'm just going to go ahead and hit plus and continue on down here so the reason they wanted OS was to include that but just in case we need it for something else I'll leave it in but we probably don't need to import os I'll go ahead and bring this in here this is going to use we'll just call this client so it's confusing because we are using the language API but it's also called text and analytics so maybe I could have left the name as text analytics I think I'm going have called it text extraction so yeah I AP olizee for the confusion but the naming here is all over the place yeah I'll probably rename this back to text analytics um well I don't know if it was called that before but see text analytics but the API is the language API anyway um so we have our client here we will go back over to here here and we'll just take their example okay and I'm going to go over to here and we have this code here we'll add it and this one I rename probably to client I prefer that as a name so begin abstract summary pull for results and then stream the results okay so I'm pretty certain that this one's done I don't think we have to restart the kernel sometimes you have to we'll go ahead and run this we'll go ahead and run this we'll go ahead and run this and so it has a problem this is called my key and my endpoint so we'll change that there we go then we'll go to here run that and so now we'll see if it summarizes and we'll just have to be a little bit patient here and there we go so there is our summary it took it and it appears to have shortened it okay so pretty straightforward I'm not sure what else we can dial in for options there could be some options here to say like how short you want it to be but I don't I don't see anything there we'd have to look up this here right and see if there's any options uh yeah so there are some options that we can uh says keyword only parameters so maybe we'll just play with this here all right so let's see if we can adjust this so maximum number of sentences to return defaults to three so we'll go ahead and copy this we'll go back over to here um uh sure overwrite we'll just say overwrite and I don't think I lost anything here um so I'm thinking do this and maybe that will work go ahead maybe just type in document equals document I'm not sure what it expects as that first parameter let's go over here and just see what it's expecting the this is documents and I'm not sure if I can do this I'm going to just try to take this out because it's expecting documents so let's try this again so documents oh it's up here it says documents list what a mess can we get an example here uh no not really I mean it seems like that should work but keyword parameters only all right so I'm going to try this it's not a big deal like I don't want to I don't really care that much if that works I'm just going to go ahead and try this say documents equals this and this looks like it's already in an array so it's already treating it as such okay so that is no good so go ahead here and just take that out and go back there and let that generate out and so we have that which is okay I suppose but I was really hoping that it would do something else I gu the question is it only summarizing the single line because um that's what it looks like to me because say Microsoft is working towards advancing uh AI through a holistic and so I think what it's doing yeah it's summarizing each of these lines and then it stitches it together as its a final thing it would be really nice if we could play around with the settings a bit but I can't seem to figure that out right now so that's um abstract is this abstract abstract abstraction let's take a look at the other type of abstraction because they're both um important to know both types so let's go back here and that's the dock so we'll close that out and so I'm going to go back to samples here and we should have another example for extraction we don't that's fine yeah it's not what I was expecting I thought there was two types maybe we have to keep going backwards here back a bit more here we go so extractive text summarization and then abstractive so open this one and then this one right so this one was the one of them okay and this is the other one so this one is the other one what's the difference they look the same begin extract summary begin extract summary ah so the only difference here is that here it says abstractive extractive okay sum abstracted summ extracted okay so let's go back over to this one here and take a look at what we have that's a summary abstracted so maybe what we can do it seems like it's doing both of them at the exact same time right yeah it does uh and so I'm going to go ahead and grab this one here here and we'll go back over to here and so I'm thinking we just go here paste this in um as such because we'd have to do it twice for it to work right yeah okay so let's see if that works what we probably could have done is we could have took the um some of this and moved it over here I'm going to go ahead and just just say result here results and I'm going to just cut this here just so that way we're not constantly running it again and again and again so I'm going to go ahead and just run that like that and then here I'm just going to save results and here I'm just going to do it twice because I'm not sure if it's just only printing the first one or not the other one so we'll go ahead and iterate that one and then we'll do this one and it shows nothing so I was guessing that it would show us something here but I don't see anything that's different okay well we made our attempt there and I think that's good enough so we'll consider uh this done for um uh text analytics there is more that can be done but I think that is sufficient so what I'm going to do is just uh put this into the repo here so that you can get access to this when you need to work with this I'm going to go ahead and just clear up some of the these things here and clear all outputs good oops I'll go to this one here and clear this one out as well good that's so I'll just go ahead and download all this download these two here and we'll go back to the exam Pro repo so that when you want to go find it you can get it has your examples I'll just press period here and going to make a new folder here this will be um I'm going to open I'm going to see me every time I I open that there uh we'll just uh try to so say text analytics and my downloads here so I have these two files make a folder here assets and we want our movie reviews there we go looks good add text great and so that one is done so if you need that you can get that from there I'm going to go ahead and stop um this compute and I will see you in the next one ciao all right let's talk about computer vision so this is when we use machine learning neural networks to gain high level understanding from digital images or videos so there are two algorithms that you're going to want to remember the first is convolutional neural networks which is CNN and the other one is going to be reoccurring neural networks RNN and in some other video I explain these in more greater detail when we're working with AI it's not super important to uh know exactly how they work but it is useful if you want to distinguish them between um Transformers uh architecture which is used in llms that can have Vision component in them or something similar um if that makes sense because rnns uh were the precursor to Transformers right and so sometimes we just like to talk about RNs to show the distinction between them but anyway we're talking about computer vision right now which is actually analyzing um uh images or videos so let's talk about the types of computer vision there are the first is image classification this is where you look at an image or video and you classify it or place it into a category we have object detection this is where it finds things in an image or video and applies labels and makes those boxes around it to show you where it is we have semantic segmentation this is where we identify segments or objects by drawing a pixel ma mask this is like way more detailed than object detection where it's individualized things in an image or video we have image analysis where you'll apply descriptive and context labels so describing what the image is so let's say an employee sitting at a desk in Tokyo we have OCR optical character recognition this is where let's say you scan something a document and it's an image format we want to extract out that raw text to work with it then we have facial detection so over at Azure we basically have um a solution for all these types of use cases for computer vision we have Azure AI Vision this analyzes images and videos extra extra TRS descriptions tags objects and tags we have Azure AI custom Vision this is basically a custom image classification where you are uh training it for your use case as opposed to the stock versions that are in Azure AI Vision we have OCR service and you know that takes um documents that are images and extracts out the text we have image analysis as described before it analyzes images we have face detection we have video analysis so um as is really good at naming their services after what they do so no confusion there uh will we try out every single one of these I don't know um for the exam it's not important to know all of them but we'll cover the most uh important uh important ones okay all right so let's take a look here at computer vision first and computer vision is actually used for a variety of different Services as you will see it's kind of an umbrella for a lot of different things but the one in particular that we're looking at here is to describe image in stream if we go over here to the documentation this operation generates description of image in a human reable language with complete sentences the description is based on a collection of content tags which also returned by the operation okay so let's go see what that looks like in action so the first thing is is that um we need to install this Azure cognitive Services Vision computer vision now we do have a kernel and these aren't installed by default they're not part of the um uh machine learning uh the Azure machine learning uh SDK for python I believe that's pre-installed but uh uh these AI services are not so what we'll do is go ahead and run it this way and you'll notice where it says pip install that's how it knows to install and once that is done we'll go run our requirements here so we have the OS which is for usually handling op like OS layer stuff we have matte matte plot lib which is to visually plot things and we're going to use that to show images and draw borders we need to handle images uh I'm not sure if we're using numpy here but I have numpy loaded and then here we have the Azure cognitive Services Vision computer vision we're going to load the client and then we have the credentials and these are generic credentials for the cognitive Services credentials it's commonly used for most of these services and some exceptions they the apis do not support them yet but I imagine they will in the future so just notice that when we run something it will show a number if there's an aster it means it hasn't ran yet so I'll go ahead and hit play up here so it goes an aster and we get a two and we'll go ahead and hit play again and now those are loaded in and so we'll go ahead and hit play okay so here we've just packaged our credentials together so we passed our key into here and then we'll now load in the client uh and so we'll pass our endpoint and our key okay so we hit play and so now we just want to load our image so here we're loading assets data.jpg let's just make sure that that is there so we go assets and there it is and we're going to load it a stream because you have to pass streams along so we hit play and you'll see that it now ran and so now we'll go ahead and make that call okay great and so we're getting some data back and notice we have some properties person wall indoor man pointing captions it's not showing all the information sometimes you have to extract it o but we'll take a look here so uh this is a way of showing mat pla lib in line I don't think we have to run it here but I have it in here anyway and so what it's going to do is it's going to um show show us the image right so it's going to print us the image and it's going to grab whatever caption is returned so see how there's captions so we're going to iterate through the captions it's going to give us a confidence score saying it thinks it's this so let's see what it comes out with okay and so here it says Brent spider Spiner looking at a camera so that is the actor who plays data on Star Trek as a confidence score 57.4% even though it's 100% correct uh they probably don't know contextual things like um uh in the sense of like pop culture like they don't know probably sarra characters but they're going to be able to identify celebrities because it's in their database so that is um uh the first introduction to computer computer vision there but the key things you want to remember here is that we use this describe in image stream uh and that we get this confidence score and we get this contextual information okay and so that's the first one we'll move on to um maybe custom Vision next hey this is Andrew Brown we are talking about the Azure AI Vision Studio which is a no code or low code playground to perform various ml Vision tasks so here we can see things like OCR spatial analysis face image analysis if you click into one you get some kind of uh UI where you can work with it so Azure AI Vision or Azure AI Vision studio is a bit confusing because it basically they make it sound like in the docs that it's its own SDK which is not the case it's it's actually utilizing a bunch of the other apis um at like computer vision face and image analysis so I just wanted to make that clear distinction in the exam guide it suggests that maybe we should know how to utilize this though we try to focus mostly on the programmatic things that are useful to you but we will take a look here just so you know where it is if you want to play around with it just in case it does appear on your exam okay all right so we are in the Azure AI vision studio all I did was go to Google type in Azure AI Vision studio and somehow I ended up over here you can see that um I'm not even logged in right now but if you look at the top here you'll notice it says cognitive do azure.com because previously the Azure AI Services were named cognitive services but obviously there was that marketing name change to make things more AI uh obvious but yeah over here you can see we have a bunch of options um if we wanted to do something like face analysis like detect a a an image in a face we can click here and we can see that it's giving us some examples if we want the reference code I suppose we can click here usually goes to the docs it's not super useful but um we can also check maybe the rest API nope that does not work but you know it gives you kind of an idea of like how you would end up utilizing this um but yeah these all go to the respective API so if we're using this one we're going to the face pii I just want to show you what I mean so I just want to uh pull up here portal. azure.com and if we were to go to let's say Azure Services here notice here on the left hand side face API so that's probably what this is utilizing uh if we have let's say the OCR that's going to be the over here on the left hand side do we have just an OCR one um I think it's computer vision but if we go into Azure AI Services I'm not sure if I have one spun up right now I don't there could be a dedicated CR API so if I go here I'll create one I just want to show you how they map up right because to me that was the most confusing part so computer vision uh API and you don't have to create this I'm just showing you as I go through this I'm going to go free here say review create and doesn't like something here I'm just going to put any kind of name I don't care what does it want now it should be fine let's go back over to here uh OCR put some numbers here on the end probably didn't like my name oh yeah acknowledge that review create we'll create that one at the same time just going to make my life a little bit easier I'm going to go over here and create one for the azri services again you don't have to do this I'm just doing this here to show you I go creating that well that one was the one I created before just to show you uh what it looks like just say uh Azure AI vision because then other fongs will cover these use cases put some numbers here on the end review create we'll just give it a moment because I just again want to match that up so it's very clear where those apis are coming from all right and so you know we going to go over to that Azure AI service here and here down below we can see all the apis it's just a lot easier to look at it this way so if we go over to let's say computer vision that just has computer vision um and if we scroll down here let's say we go to language that's just language document intelligence it might be this API it used to be called form recognizer but now it's called that over to translator and so I'm not exactly seeing where the mapping is but it's really important to understand where those things are going because it does get really confusing I know that we just launched um the other one here I think it was under computer computer vision and so yeah not exactly sure it does show Vision Studio here which is interesting so if we click through to here we'll end up in Vision Studio as well still says I'm not logged in which is uh interesting but I want to see where that OCR API is coming from here so we go back to this one and we'll click it and we'll say um view SDK reference and I'm going to go let's just say python to make my life a little bit easier and what is the name of the package this one is image analysis so it's coming back to that image analysis one here um I guess my question is where is that endpoint like which one is it utilizing and so it's saying Vision endpoint making me think that it's using the computer vision endpoint is probably the case here MH so let's go take a look at that so let's just say computer vision API Azure and we'll go over to here and again we will do this in actual Labs but again just to help you kind of map that information because it does get really confusing and so it looks like that not all of them but um definitely the OCR and image analysis are going to be within the computer vision endpoint and they may have separate um uh they might may have the same image analysis when or separate ones but we'll cover that in the content I just wanted to show you that it's confusing just for me as well and I've already done the uh a similar course with this and covered all these Services before but uh this is just the nature of um Microsoft marketing is that they start to make it very muddy when they're trying to meet everyone's business use case from every angle and um yeah just showing my confusion to you okay there you go so the image analysis SDK can analyze various visual features and images such as detecting adult content identif Ying brands or objects and recognizing human faces key features here is going to be dependent on whether you're using version 4 which is the latest version recommended uh for most use cases or version 3.2 which offers a broader range of features um which you may have to use this if you are looking for those specific feature sets so for uh version four we got retext captions Den captions tags object detection custom image classification people smart objects and then in version 3.2 you can see there are some different things like celebrities adult content landmarks things like that one thing I want to point out is that when you are utilizing the SDK you're using the computer Visions resource endpoint there's no image analysis um uh resource in Azure it's just more confusion uh for for people trying to match up the marketing versus um the the portal versus what's in the code um what kind of type of image analysis can we do let's look at it in more detail here so some are in four and some are in um 3.2 we say preview only but at this point a lot of these are kind of out of preview so maybe I just needed to update this because I'm pretty sure this is now out of preview and this is now available but we have model customization so create custom models for image classification detection object we have read text from images so extract text from images using OCR detect people and images so identify and locate people and images generate image caption so create human readable captions for images detect objects so identify objects and locations images and notice just if it doesn't say only then it's for both um tag visual features so tag objects scenery and actions and images get the area of Interest smart uh smart crops detect Brands categorize an image detect faces detect image types detect domain specific content detect the color scheme moderate content images so there you go um but you can see there's some stuff that's in four some stuff that's in 3.2 and some that are shared okay hey this is Andrew Brown from exam Pro and we are looking at optical character recognition also known as OCR and this is the process of extracting printed or handwritten text into a digital and editable format so OCR can be applied to photos of street signs products documents invoices bills Financial reports articles and more and so here's an example of us extracting out nutritional data or nutritional facts off the back of a food product so Azure has two different kinds of apis that can perform OCR they have the OCR API and the read API so the OCR API uses an older recognition model it supports only images it executes synchr synchronously returning immediately when uh it detects texts it's suited for Less texts it supports more languages it's easier to implement and on the other side we have the read API so this is an updated recognition model supports images and PDFs executes a synchronously paralyzes tasks per line for faster results suited for lots of Texs supports fewer languages and it's a bit more difficult to implement and so when we want to use this service we're going to be using uh computer vision SDK okay let's take a look at some of our OCR capabilities here uh and I believe that's in computer vision so we'll go ahead and open that up at the top here we'll install computer vision as we did before very similar to the other computer vision tasks but this time we have a couple of ones here that'll explain that as we go through here we'll load our keys we'll do our credentials we'll load the client okay and then we have this um function here called printed text so what this function is going to do is it's going to uh print out the results of whatever text it processes okay so the idea is that we are going to feed in an image and it's going to give us back out the text for the image so we'll run this function and I have two different images CU I actually ran it on the first one and the results were terrible and so I got a a second image and it was a bit better okay so we'll go ahead and run this it's going to show us the image okay and so this is the photo and was supposed to extract out Star Trek the Next Generation but because of the artifacts and size of the image we get back uh not English okay and so you know maybe a high resolution image it would have um a better a better time there U but that is what we got back okay so let's go take a look at our second image and see how it did and this one I'm surprised that it actually extracts out a lot more information you can see it really has a hard time with the Star Trek font but we get Deep Space 9 n a visitor tells all Life Death some errors here so it's not perfect um but you know you can see that it does something here now there is the O this is like for OCR where we have like for very simple images and text this is where we use the recognized printed text in stream but uh if we're doing this for larger amounts of text and we want to do this uh want this analyzed asynchronously then we want to use the read API and it's a little bit more involved um so what we'll do here is load a different image and this is a script we'll look at the image here in a moment um but here we read in stream and we create these operations okay and what it will do is it will asynchron asynchronously send all the information over okay uh so I think this is supposed to be results here minor typo and um we will go ahead and give that a run okay and so here you can see it's extracting out the image if we want to uh uh see this image I thought I uh I thought I showed this image here but I guess I don't yeah it says plot image here should show us the image uh path it's up here it doesn't want to show us it's funny because this one up here is showing us no problem right um well I can just show you the image it's not a big deal but I'm not sure why it's not showing up here today so if we go to our assets here I go to OCR uh I'm just going to open this up it's opening up in Photoshop and so this is what it's transcribing okay so this is a thing this is like a guide to Star Trek where they talk about like you know what what makes start Trek start Trek so just looking here it's actually pretty darn good okay but like read API is a lot more uh efficient because it can work uh um a seenly and so when you have a lot of text that's what you want to do okay um and like it's feeding in each individual line right so that it can be more effective that way um so let's go look at some handri stuff so just in case the image doesn't pop up we'll go ahead and open this one and so this is a a a handwritten note that uh William Shatner wrote to a fan of Star Trek and it's basically incomprehensible I don't know if you can read that here but see was very something he was something hospital and healthy was something he was something I can't even read it okay so let's see what uh the machine thinks here and uh it says image path yeah it's called path let's just change that out go ahead and run that and run that there and we'll go ahead and run it and here we get the image so uh poner us very sick he was the hospital his Bey was Etc beat nobody lost his family knew Captain Halden so reads better than how I could read it honestly like it is it's really hard right like if you looked at this like that looks like difficult was be healthy I could see why it's guessing like that right dying that looks like dying to me you know what I mean so you it's just poorly hand hand Rd but I mean it's pretty good for what it is so uh yeah there you go hey this is Andrew Brown from exam Pro and we are taking a look here at custom vision and this is a fully managed no code service to quick build your own classification and object detection ml models the service is hosted on its own isolate domain at www.com vision. so the first idea is you upload your images so bring your own labeled images or custom Vision to quickly add tags to any unlabeled data images you use the labeled images to teach custom Vision the concepts you care about which is training and you use a simple rest API that calls uh to quickly tag images with your new custom computer vision models so you can evaluate okay so when we launch custom Vision we have to create a project and with that we need to choose a project type and we have classification and object detection reviewing classification here you have the option between multi-label so when you want to apply many tags to an image so think of an image that contains both a cat and a dog you have multiclass so when you only have one possible tag to apply to an image so it's either an apple banana Orange it's not uh multiples of these things you have object detection this is when we want to detect various objects in an image uh and you also need to choose a domain a domain is a Microsoft managed data set that is used for training the ml model there are different domains that are suited for different use cases so let's go take a look first at image classification domains so here is the big list the domains being over here okay and we'll go through these here so General is optimized for a broad range of image classification tasks if none of the uh uh if none of the other specified domains are appropriate or you're unsure of which domain to choose select one of the general domains so G uh or A1 is optimized for better accuracy with comparable inference time as general domain recommended for larger data sets or more difficult user scenarios this domain requires more training time then you have A2 optimized for better accuracy with faster ad times than A1 and general domains recommended for more most data sets this domain requires less training time than General and A1 you have food optimized for photographs or dishes of as you would see them on a restaurant menu if you want to classify photographs of individual fruits or vegetables use food domains uh so then we have optimize for recognizable landmarks both natural and artificial this domain works best when Landmark is clearly visible in the photograph this domain works even if the land mark is slightly um obstructed by people in front of it uh then you have retail so optimize for images that are found in a shopping cart or shopping uh website if you want a high Precision classifying uh classifying between dresses pants shirts use this domain compact domains optimized for the constraints of real-time classification on the edge okay then uh we have object detection domains so this one's a lot shorter so we'll get through a lot quicker so optimize for a broad range of object detection tasks if none of the uh other domains are appropriate or you're unsure of which domain choose the general one A1 optimized for better ACC and comparable inference time than the general domain recommended for most accurate region locations larger data sets or more difficult use case scenarios the domain requires more training results are not deterministic expect uh plusus 1% mean average Precision difference uh with the same training data provided you have logo optimized for finding Brands uh logos and images uh products on shelves so optimized for detecting and classifying products on the shelves so there you go okay so let's get some uh more practical knowledge of the service so for image classification you're going to upload multiple images and apply a single or multiple labels to the entire image so here I have a bunch of images uploaded and then I have my tags over here and they could either be multi or singular for object detection you apply tags to objects in an image for data labeling and you hover uh your cursor over the image custom Vision uses ml to show bound uh bounding boxes of possible objects that have not yet been labeled if it does not detect it you can also just click and drag to draw out whatever Square you want so here's one where I tagged it up quite a bit you have to have at least 50 images on every tag to train uh so just be aware of that when you are tagging your images uh when you're training your model is ready when you and you have two options so you have quick training this trains quickly but it will be less accurate you have Advanced Training this increases compute time to improve your results so for Advanced Training basically you just have this thing that you move to the right uh with each iteration of training are ml model will improve the evaluation metrics so precision and recall it's going to vary we're going to talk about the metrics here in a moment but the probability threshold value determines when to stop training when our evaluation metric meets our desired threshold so these are just additional options where when you're training you can move this left to right uh and these left to right okay and then when we get our results back uh we're going to get um some metrics here so uh we have evaluation metric so we have Precision being exact and accurate selects items that are relevant recall such sensitivity or known as true positive rate how many relevant items returned average Precision it's important that you remember these because they might ask you that on the exam so for uh cut when we're looking at object detection and we're looking at the evaluation metric outcomes for this one we have Precision recall and mean average Precision uh once we've deployed our pipeline it makes sense that we go ahead and give it a quick test to make sure it's working correctly so you press the click quick test button and you can upad Lo your image and it will tell you so this one says it's Warf uh when you're ready to publish you just hit the publish button and then you'll get uh some prediction URL and information so you can invoke it uh one other feature that's kind of useful is the Smart labeler so once you've it loaded some training data within it can now make suggestions right so you can't do this right away but once it has some data it's like it's like kind of a prediction that is not 100% guaranteed right and it just helps you build up your training data set a lot faster fter uh very useful if you have a very large data set this is known as ml assisted labeling okay all right so let's take a look at custom Vision so we can do some um classification and object detection so um the thing is is that it's possible it's possible to launch custom Vision through the marketplace so if we go we're not going to do it this way if you type in custom Vision it never shows up here but if you go to the market Marketplace here and type in custom vision and you go here you can create it this way but the way I like to do it and I think it's a lot easier to do is we'll go up the top here and type in custom vision. and you'll come to this website and what you'll do is go ahead and sign in it's going to connect to your Azure account and once you're in you can go ahead here and create a new project so the first one here is I'm just going to call this the Star Trek crew we're going to use this to identify different Star Trek members we'll go down here and uh we haven't yet created resource so we'll go create new my custom Vision resource we'll drop this down we'll put this in our Cog Services uh we'll go stick with um Us West as much as we can here we have fo Ando fo is blocked out for me so just choose so I think fo is the free tier but I don't get it and um once we're back here we'll go down below and choose our standard and we're going to have a lot of options here so we have between classification and object detection so classification is when you have an image and you just want to say what what is this image right and so we have two modes where we can say let's apply multiple labels so let's say there were two people in the photo or whether there was a dog and cat I think that's example that use a dog and a cat or you just have a single class where it's like what is the one thing that is in this photo it can only be of one of the particular categories this is the one we're going to do multiclass and we have a bunch of different domains here and if you want to you can go ahead and read about all the different domains and their best use case but we're going to stick with A2 this is optimized for so that's it's faster right and that's really good for our demo so we're going to choose General A2 I'm going to go ahead and create this project and uh so now what we need to do is start labeling our our our content so um what we'll do is I just want to go ahead and create the tags ahead of time so we'll say Warf we'll have uh data and we'll have Crusher and now what we'll do is we'll go ahead and upload those images so you know we uploaded in the jupyter notebook but it was totally not necessary so here is data because we're going to do it all through here and we'll just apply the data tag to them all at once which saves us a lot of time I love that uh we'll upload now uh Warf and I don't want to upload them all I have this one quick test image we're going to use to make sure that this works correctly and I'm going to choose Warf and then we'll go ahead and add Beverly there she is Beverly Crusher okay and so we have all our images in I don't know how this one got in here but it's underw it works out totally fine so uh what I want to do is uh go ahead and train this small because they're all labeled so we have a ground truth and we'll let it go ahead and train so we'll go and press train and we have two options quick train or Advanced Training Advanced Training where we can increase the time for better accuracy but honestly uh we just want to do quick training so I'll go ahead and do quick training and it's going to start its iterative process notice on the left hand side we have probability threshold the minimum probability score for a prediction to be valid when calcul calculating precision and recall so we uh the thing is is that if it doesn't at least meet that requirements it will quit out and if it gets above that then it might quit out early just because it's good enough okay so training doesn't take too long it might take 5 to 10 minutes I can't remember how long it takes but uh what I'll do is I'll see it back here in a moment okay all right so after waiting a short little while here looks like our results are done we get 100% um match here so these are our evaluation metrics to say whether uh the model was uh uh achieved its actual goal or not so we have Precision recall and I believe this is average Precision uh and so it says that it did a really good job so that means that it should have no problem um matching up an image so in the top right corner we have this button that's called quick test and this is going to give us the opportunity to uh quickly test these so what we'll do is browse our files locally here and uh actually I'm going to go to uh yeah we'll go here and we have Warf uh and so I have this quick image here we'll test and we'll see if it actually matches up to be Warf and it says 98.7% War so that's pretty good I also have some additional images here I just put into the repost to test against and we'll see what it matches up cuz I thought it'd be interesting to do something that is not necessarily uh them but it's something pretty close to um you know it's pretty close to what those are okay so we'll go to crew here and first we'll try Hugh okay and Hugh is a borg so he's kind of like an Android and so we can see he mostly matches to data so that's pretty good uh we'll give another one go Marto is a Klingon so he should be matched up to Warf very strong match to Warf that's pretty good and then palaski she is a doctor and female so she should get matched up to Beverly Crusher and she does so this works out pretty darn well uh and I hadn't even tried that so it's pretty exciting so now let's say we want to uh go ahead and uh well if if we wanted to um make predictions we could do them in bulk here um I believe that you could do them in bulk but anyway yeah I guess I always thought this was like I could have swore yeah if we didn't have these images before I think that it actually has an upload option it's probably just a quick test so I'm a bit confused there um but anyway so now that this is ready what we can do is go ahead and publish it uh so that it is publicly accessible so we'll just say here a crew model okay and we'll drop that down say publish and once it's published now we have this uh public or El so this is an endpoint that we can go hit pragmatically uh I'm not going to do that I mean we could use Postman to to do that um but my point is is that we've basically uh figured it out for um classification so now that we've done classification let's go back here to uh the vision here and let's now let's go ahead and do object detection okay all right so we're still in custom Vision let's go ahead and try out object detection so object detection is when you can identify particular items in a scene um and so this one's going to be combadge that's what we're going to call it because we're going to try to detect combadge we have more domains here we're going to stick with the general A1 and we'll go ahead and create this project here and so what we need to do is add a bunch of images I'm going to go ahead and create our tag which is going to be called combadge uh you could look for multiple different kinds of labels but then you need a lot of images so we're just going to keep it simple and have that there I'm going to go ahead and add some images and we're going to go back um a couple steps here into our objects and here I have a bunch of photos and we need exactly 15 to train so we got 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 and so I threw an additional image in here this is the badge test so we'll leave that out and we'll see if that picks up really well and yeah we got them all here and so we'll go ahead and upload those and we'll hit upload files okay and we'll say done and we can now begin to label so we'll click into here and what I want to do if you hover over it should start detecting things if it doesn't you can click and drag we'll click this one they're all combadges so we're not going to tag anything else here okay so go here hover over is it going to give me the combadge no so I'm just draag clicking and dragging to get it okay okay do we get this combadge yes do we get this one yep so as simple as that okay it doesn't always get it but uh most cases it does okay didn't get that one so we'll just drag it out okay it's not getting that one it's interesting like that one's pretty clear but uh it's interesting what it picks out and what does what it does not grab a so it's not getting this one probably because the photo doesn't have enough contrast and this one has a lot hoping that that gives us more data to work with here yeah I think the higher the contrast it's easier for it to uh um detect those it's not get in that one it's not getting that one okay there we go yes there are a lot I know I have some of these ones that are packed but there's only like three photos that are like this yeah they have badges but they're slightly different so we're going to leave those out oops I think it actually had that one but we'll just tag it anyway and hopefully this will be worth the uh the effort here there we go I think that was the last one okay great so we have all of our tagged photos and what we can do is go ahead and train the model same option quick training Advanced Training we're going to do a quick training here and notice that the options are slightly different we have probably threshold and then we have overlap threshold so the minimum percentage of overlap between predicted bounding boxes and ground truth boxes to be considered for correct prediction so I'll see you back here when it is done all right so after waiting a little bit a while here it looks like um it's done it's trained and so precisions at 75% so Precision the number will tell you if a tag is predicted uh by your model How likely that it's likely to be so How likely did it guess right then you have recall so the number will tell you out of the tags which should be predicted correctly what percentage did your model correctly find so we have 100% uh and then you have mean average Precision this number will tell you the overall object detector performance across all the tags okay so uh what we'll do is we'll go ahead and do a quick test on this model and we'll see how it does I can't remember if I actually even ran this so it'll be curious to see the first one here um that's not as clearly visible it's part of their uh uniform so I'm not expecting to pick it up but we'll see what it does it picks up uh pretty much all of them the exception this one is definitely not a comp badge but uh that's okay only show suggests obious the probabilties above the selected threshold so if we increase it uh we'll bring it down a bit so there it kind of improves it um if we move it around back and forth okay so I imagine via the API we could choose that let's go look at our other sample image here um I'm not seeing it uh where did I save it let me just double check make sure that it's in the correct directory here okay yeah I saved it to the wrong place just a moment um I will place it just call that badge Test 2 one second okay and so I'll just browse here again and so here we have another one see if it picks up the badge right here there we go so looks like it works so uh yeah I guess custom vision is uh pretty easy to use and uh pretty darn good so what we'll do is close this off and make our way back to our Jupiter labs to move on to um our our next uh lab here okay Azure AI document intelligence formally form recognizer is a specialized OCR service that translates printed text into digital editable content and preserves the structure and relationships of form like data so here's an example of a um an invoice and it's extracting out that information you can see those uh purple or blue lines showing you that it's selecting uh text out of the image document intelligence can automate data entry in your applications and enrich your document search capabilities it can identify key value pairs selection marks table structure uh it has output structures uh for the original file relationships bounding boxes confidence scores um Azure AI document intelligence is composed of custom document processing models which we do do in the labs uh pre-built mods for invoices receipts IDs business cards uh and layout models so there you go hey this is Andrew Brown and we are taking a look at document intelligence Studio this is a way to visually explore understand train uh stuff with a no code approach um so this is at document intelligence. azure.com if you try to search for it in um Azure so if you go portal azure.com I found that I could not find it through here so that happens a lot if you go to document intelligence it's just going to want you to spin up um a resource which obviously want to use Azure AI Services which has document intelligence here now when I first use this service there weren't that many pre-built models now there are a lot um as you can see there are a ton here but you know if we wanted to use receipts and we'll use receipts here because we already did this programmatically maybe that video comes after this one or before this one but do it somewhere in the course I just want to show you how we would use a no code solution for this so let's go ahead and click on receipts and I'm going to drop down choose my subscription but we could also just go here and provide the API endpoint so it's up to us how we want to do that but I'm going to just go ahead and say API endpoint here as I feel that is a much faster way for us to do it so I'm going to go ahead and grab my key and place it in here and I'm going to go over to here and grab the document intelligence endpoint and drop this whoops drop this up here and say I understand we'll go ahead and confirm we'll say finish and so oh they already have a receipt there for us and so we can go ahead and just run an analysis and we got a nice 404 so clearly it's a really great program we'll try this again 404 let's go to this sample 404 we'll analyze the current document I guess we could just change our options how we want to analyze them and so for some weird reason we're getting a 404 so that is a bad start to this but I'm going to go ahead and try to upload the um the receipt that we used prior so that was in if you don't know where that is um if you go to uh exam Pro as your examples and you go to form recognizer we have a receipt right here so I already have this downloaded I'm going to just upload this quickly and see if that helps and I'm getting issues um trying to upload the receipts so we're really having a hard time time here and so I'm going to just click here again and try to authenticate but this time I'm just going to choose the subscription I'm going to try to find where this resource is here so here um we have not this one but this one this one is in a resource group called AI manage workloads we created this earlier in the course you should already have this if you do not you have to go create it um here it says to use document intelligence you need to create an a subscription creating the resource for usage and buil oh so it's actually going to create the new resource whereas here we would just provide it but I did do that so maybe we'll just make it even though we already have it we'll just make it again we'll just say um doc intelligence Studio because it's having a hard time for whatever reason we'll just say uh my doc Intel whatever it is we'll put some numbers here on the end um I'm going to go with eastus here today and we'll just choose the free tier sometimes the standard tier has some differences I'm going to go with standard we'll go ahead and hit finish and so maybe this might mitigate our issue maybe this thing still doesn't work I don't know uh for things not working Azure is very common so just have your confidence okay we'll give it a moment there to create the resource all right so actually just kind of curious what resources created underneath because I want to know is it Azure service or did it make something let's go over to our resource groups and take a look here um and this one was called doc here it is Doc and it created uh document intelligence now I think that it should have worked with the other one but we just want to guarantee that this is going to work here today we don't want to goof around here so there we go and so you can see that this can analyze um documents there right now of course we can do all of this via the API we don't have to um do it this way but uh it's just kind of show you that you have this ability to do this um adabs has the basically the same thing it's like the first time you clicking the service for theirs it will show you this but it looks like that Azure seems to have um at least right now it appears they have more options I'm not sure but uh you know again trying to run this here there we go so you can see um it can do stuff so yeah that's all I wanted to show you for now here the next thing we'll we'll look at is custom models but for now this is the intro to that I'm going to go ahead and tear down um this Resource Group if I can yeah there it is find it here and I'll see you in the next one okay ciao hey this is Andrew Brown and we are back taking a look at document intelligence studio and specifically how to train a custom model there could be a way to do this um programmatically but for our purposes this should be good enough so let's go ahead and get to it so we have two extraction model and classification model um which one should we train I mean I wrote to do extraction models let's go ahead and do that apparently they have videos here uh if there are videos to make this super easy would love to do that I'm just going to go ahead and click through and figure this out so say my extract model and we'll just say this is my description we'll go ahead and hit continue and we'll choose your subcription we will make a new group here we'll call this um doc AI Studio I'm just going to put two put any number you want there just because I have one deleting I don't want to have a conflict here we're going to create a new resource so my doc AI resource I'll put some random numbers here I'm going to choose East us I'm going to choose standard since I'm pretty comfortable with standard I'm going to go with whatever the latest one is here and then we'll choose our training data source so this do we have to have this set up beforehand so it looks like we do have to have some uh data set up pre uh prior to this and that is going to be something I'm going to have to figure out so give me a moment and let me go find some data for us um to work with okay all right so I'm going to have to create some documents for us um basically some form so I'm going to open up word make some documents export them to PDF then I'll share them in the repo I'm not going to share that on screen because um I don't think you want to watch me making forms it's not super hard to do that but give me a moment I'll be back in just a moment with five documents uh that we can utilize I'm going to try to make the examples a little bit complex uh for our use cases okay so I just want to show you that I went out to the internet I just searched for like a d and form um and I'll just try to fill this in with random data for five of them I save those to PDF and we'll be back in just a moment okay all right I'm back I've created Five uh PDFs and I'm just going to place them uh here in the repo so that if you want to go ahead and utilize them you can too it was quite the pain to generate PDFs I'm not sure why it takes so long to turn docs into PDFs but that's okay um so here I'm just going to make myself a new folder this one's going to be called custom extraction model uh document let's just say Doc here and I'm going to grab these uh five PDFs and drop them in here so these are D andd sheets they're not fully filled out but they're filled out enough that they should serve our purpose um or we'll find out if it doesn't work out as planned um but uh yeah we'll find out here in just a moment so they said we're going to need um a storage account so we'll go ahead and make one right now go ahead and make a new one and this will be a new work CL this will be Doc uh AI custom model and we'll just call this doc custom AI some numbers here I'm going to stick with um East us if we can not sure why this is giving me such odd odd options here say East us there we go um primary service yep laot of storage there we go they've changed the UI here since just working with this recently literally yesterday they' changed the UI on me here which is not great because uh that can uh really mess up a lot of my videos so here we have primary workload why are they asking me so many darn questions um uh what why like why do we even have to answer these or can I just leave this blank let me go here to say de can I do that what the heck Azure please please stop making useless changes they're just making things more confusing so go ahead and create that notice I did not have to tell it it's primary workload maybe the primary service probably do have to select we'll go ahead and deploy that and wait for that to be ready okay all right so that is now deployed we're going to make our way over to back to our document uh intelligence Studio we'll go ahead and create ourselves a project so we'll say my new project project I do not care about description we're going to choose or description I should say and in here we'll have our doc AI custom model we'll create a new resource my doc AI resource we'll just put some numbers here on the end doesn't really matter I'm going to go with e us here today I'm going to go with standard we're going to go continue and then we want to have our training uh source and oh could we have just created one here initially this entire time all right well that's fine but we will have to create some uh blob storage here so let's go ahead and just say uh you know my blob and we will have to upload those files there um I'm going to leave it to no folder path and we'll go ahead and create that project while that is going I'm go over to here and it should um eventually show us this here we'll go over to Containers we should get a container here so I'm going to wait for this to finish provisioning and then I'm going to add those models in there okay I mean those PDFs sorry yeah all right so here we are and apparently we can just drag our data in here that's even easier than me having to place it into blob storage give this a refresh here and yeah it is there now um but I guess this is drag and drop so I have them all off screen here just going to go ahead and drag them on in and it says start labeling now so we provide two ways to start your labeling process however you need to label a particular document you can skip the step and proceed so we have run layout or Auto Lael let's go with auto label and ohh I'm not exactly sure what we do here maybe we go back I I wasn't expecting that so we I guess just run the layout because those models didn't look exactly how they would fit for hours so I wasn't sure what to pick there okay and looks like it has um found some data it's going good so far okay and so now I imagine it's basically selected stuff okay then we just basically tell what field this is we just say character um field there we go and zoom in here so this one is race field class field so you're starting to get the idea here and so I'm just going to hopefully I don't have to go through every single field here but um we'll go ahead and train this and we'll just give it you know my DND ID and detect or DND and we'll say neutral that's fine we'll go ahead and hit train and we'll go to our models and we're waiting for this to run so I'm going to run this and I'm going to wait till it completes okay all right so I'm just taking a look here seeing how our model's doing I'm assuming at some point it will be uh done here I'm just giving this a nice refresh here says it's running okay uh well oh by the way did we go through all our sheets and label them uh no we didn't we didn't but oh well I mean as long as it tries to extract out some information that's fine but you know if you were doing this for real you'd obviously go through and label all of them they had the auto labeler but I just didn't trust it because um it didn't seem like it would fit any of our stuff but again just waiting for this to finish um I'm going to go look up how long this takes okay all right so after waiting a while it looks like our model is ready so maybe we can go ahead and test our model out so Mar files will be updated uploaded to to the training data set uh okay so I mean I'll just test with an existing document now of course probably you'd want a new document for this and we will run the analysis against our new document and there we can see some extraction of information so it gives you kind of an idea in terms of how you would go ahead and uh utilize this um but yeah that's pretty straightforward there now how would you work with this programmatically I'm not exactly sure I'm sure there is some way that you would be able to access yours um because yeah it seems like there would be some kind of endpoint or something but for the purpose of certification this is all you really need to know here okay so we're just going to keep it simple there um and I guess just clean this up so I think I committed these here I'll just commit these files in case uh well obviously you'll want them for later so if you want to follow along here yourself but we'll go over to um whatever this Resource Group is here and just tear this down so this is this one here and I'm going to go ahead and delete that there and I think that should get rid of everything um the reason I say that is because we've trained that model but where that model could be as a resource I'm not sure yeah I I think it's getting teared down so hopefully we don't have something lingering there but uh yeah there you go and I will see you in the next one all right ciao hey this is Andrew Brown this video we're going to take a look at Azure AI form recognizer so let's go over to Azure Azure AI services and underneath we should have something for form recognizer so I'm just trying to find where that is um oh it's called document intelligence okay so that is what we're going to utilize there and now we're just double check to make sure that it appears as a possible endpoint for us uh under here so we're going to go here and yes it is so we can use our unified a Pi now I did this uh 3 years ago with the free uh AI 900 whether you're doing the AI 900 the AI 102 you're going to want to know how to do this um but let's go ahead and see if we can take this older example that worked totally fine and move it over because as far as I can tell it's still using this API and this one actually has a a much um more modern format than the um uh cognitive Services API so we should be able to just use this wholesale it should just work um the only key difference is that we're going to use the the unified um API here okay so what I want to do is get my compute uh started up here as per usual and sometimes this happens where I can't click Start so just give it a hard refresh here and we will whoops click here maybe what I did is I clicked this one by accident nope it doesn't really matter sometimes happens and so I'll spin that up and wait for our jupyter notbook to become available okay all right so our environment is up and running let's go ahead and launch Jupiter labs and I believe uh what we did here for form recognizer is that we would um feed it in a receipt and OCR that information so we're going to do the exact same thing here we'll hit build let it do whatever it wants here um give this a moment here and I think before I called this yeah form recognizer it is the document intelligence API but just so that it's less confusing I'm going to call it form recognizer here so we'll make a new folder here calling it form recognizer and in here I'm going to just make a new notebook called form recognizer once the CPU decides to uh stop complaining so much we'll go with 3.10 here say form recogn izer there we go and so we should be for the most part able to Port this code over so the first thing we'll want to do is do a pip install still don't remember why I was installing it that way with the additional line there must have been a good reason for that at the time so we'll do that um so that will get form recognizer installed and then the next thing will be our Imports yep that makes sense we'll go ahead and grab these I do not remember what p is must be a way working with images python let's go take a look here is a python image Library okay sounds good works for me uh next we'll need to get our key so this should be pretty much the same okay well obviously it's not co uh cognitive key anymore but we'll go over and grab these as per usual so in our Azure AI Services I'm going to grab my key and we will paste that in there and we also need the endpoint so down below we'll grab the document intelligence one over here and paste that on in and we'll continue on with our stuff so we'll need our client nothing new here we'll go down here and we'll grab our path and then we will try to analyze this here good so yeah we're going to get that receipt um this is just going to go plainly into here I'm not going to uh have a path like this and here it says we're going to um open that file and then it's going to be begin to recognize the receipt we're going to get a results and then the last thing here we're going to do is print our print out our results so we have a few prints here um anyway we we'll run them here in just a second but we need to get that image in here so in the old free a AI 900 if we go to assets and we go to OCR we can go ahead and grab our uh receipt clearly we have a lot of things that we can um OCR here which makes me think that when I did this originally um no I guess it would have been for the form because in OCR we probably did more examples yeah handwriting yeah exactly so um for form writing or for the um for the receipt we'll just download this individual receipt so here we have one I think I just pulled it off the internet it's nothing fancy it's clearly from a very long time ago and so we're going to want to upload that so go over to here and remember the upload button is here I'm going to pause um so I'm not exposing all of my directories here but just be back and upload it there we go so we have our receipt in place and let's go ahead and just start running the rest here so we will run our Imports and we'll run our keys once this is done importing there we go and then we'll run the client and then we'll run the receipt sometimes we've had to say relative here I'm not sure why but we'll see if that's still an issue here and no it's no issue okay great it's really nice when you can pull up code from three years ago and it still works no problem um that makes me happy but that's not always the case some of these Labs we had to redo um and then obviously there's a lot more changes there so we'll go ahead and run this so that is the actual structure of the data so if we actually want to get anything useful out here we'll grab the fields if we go here and take a look you'll see there's Fields okay we'll run that I can by the way I can hit enter I keep uh going up here or maybe it's like shift enter yeah I keep hitting this button here it's just out of habit but here we now we're getting a little bit more information and so we're going to go ahead and just grab something in particular here right we get the merchant name so just carefully look at this and you can see like here it says get Merchant name but uh you know if we wanted to get something like the merchant phone number we could probably just Swap this out here as such right and get that number so hopefully that is clear um and that pretty much demonstrates the form recognizer very very easy so I'll just go ahead and clear this out we'll call this one done and uh yeah I'll just go ahead reset this get it into the repo and then we'll just stop our environment here we can move on so just go back a step here and ahead and download these two I don't need to download the receipt I already have it so we'll go ahead and download this and I'll just open this hit period for okay and I'll just make a new folder here this will just be form recognizer and we'll bring in that notebook and that image there okay so those are now both there um yeah I'll just commit that easy super easy okay great um yeah and we'll just go ahead and stop our compute there and I'll see you in the next one okay ciao hey this is angrew brown and in this video we're going to take a look at using uh the speech API um for Azure so what I'm going to do here is uh make my way over to our compute normally I have this open but uh I closed it from the last time we're here here and so we're running our compute in the machine learning uh studio so ml Studio here no not AI Studio but ml here it is azure machine learning or uh I believe it's called the studio there I've just called our workspace I work AI workspace I go ahead and launch the studio and then from here we're going to go onto the left hand side under compute we're going to go here and start our compute so we want to work um uh with the speech service over here and we do not need to create one in isol I don't think we do but let's go take a look here to the Azure AI services and I just want to see if it's integrated into here it is so that means that we can continue to use um uh this as our key and endpoint um the question is what is the library that we're going to use now it used to be aure cogn uh cognitive services speech but it may have changed since then so I'm going to go take a look here and just say Azure AI speech API and just see if there's a new one because there could be a new one another thing that we could find out is if I click into um into the one I already have existing now you haven't created one of course but um I think before I had created one here and if I go into here sometimes they have quick starts and so I'm just curious here if they show that here they do not what's interesting is they have a speech studio so let's just click into here and see what we have because maybe this would also appear in Azure AI Studio or Azure yeah Azure AI studio so we have some stuff here where you can I guess get started with it this is not how I want to work with it I want to work with it programmatically because that's how you should learn it as well and so I'm really curious um what is the API we're going to use so I'm going to go look for that while this compute is starting up so just give me a moment I'll be back in just a second all right so I've looked it up and it appears that the um the one that is being shown here is this one now the thing is is that a lot of the apis have been uh being changed over from being Azure cognitive Services speech to a newer one um but this is what they're still showing here so maybe in the future this is going to change but for now this is what it is and so we're going to stick with that um so now that our computer's running I'm to go ahead as per usual and open this up in Jupiter lab and so we'll just give that there a moment to open okay great I to say uh build which is totally fine and obviously we've been doing a lot of different stuff in here I'm just going to close out some of our tabs here and I want to back out to AI I'm going to make a new folder here we're going to call it speech okay and when in within here I think probably what we'll do is text to speech first so that might be a very easy one we can do so I'm going to go here and make a new notebook and I'm going to choose um 3.10 here and I'm just going to rename this to text to speech there we go and I'm G to go ahead and bring in this as the way we're going to install this here okay so we do that so that is good um I'll bring some uh documentation just in case you are looking for the same stuff that I'm looking I'm looking at so go ahead and grab this link up here for you and we'll just say resources and we'll paste that on in here um so that's that there and it looks like we have some options we have text to speech and speech to text so and then we have um speech translation so we have three things that we can do here let's go with text to speech first okay and so we can see here we have a couple Keys we need to add um here they're actually creating a net application which seems to be a little bit more extreme I would rather just work with python um and we are working with python so I don't think this is what I want to do um some of this is relevant but I definitely do not want to uh create a a full thing here so let's go see if we can find um the SDK example for this and so just give me a moment I'm going to go take a look okay all right so um I found the repo by Azure so maybe we can make sense of it um Azure not the best at uh providing us the information or resources we need but that's okay I'm here to get us through it so not a big deal um and so you know I want to do text uh to speech and so here there's a lot of examples but maybe we'll try this one here and we'll also try this one so here we have speech synthesis and so we definitely would have to do a speech config here and we need to use a synthesizer um but this doesn't look like text of speech but hold on we also have this one here which might be simpler let going to take a look here yeah they do not make it easy here do they okay so you know I when I make these videos I always like to pull from somewhere so you see where I'm pulling from but I I do have instructions off screen so um I don't always do them exactly but this is the one I prepped ahead of time and I just cannot find uh the same stuff and so I think the only way we're really going to be able to do this is if I just work with my existing text and that's what I'm going to have to do so for this one we're just going to have to type it out unfortunately it's the only way um so I do apologize for that but you know I can only do what we can do so let's go ahead and do an import OS the next thing we're going to do is import Azure cognitive Services Cog native Services speech and we're going to bring that in as speech SDK okay so we'll put that in there so hopefully it will import both of those and if I spell it wrong that's where we're going to run into an issue so I'm not going to guess here I'm just going to copy it and let's paste that in here now nope I think I'm typing it wrong so Cog ni T services do speech as speech SDK so that is definitely uh definitely correct and um we'll try this again because maybe the top one didn't finish and now it's fine so I think it was just that the time I ran that this wasn't ready and so that's probably the reason why so we're going to need a couple things we're going to probably need uh an API key as per usual and maybe an endpoint so I'm going to grab those from our other ones doesn't really matter which one so I'm going to go here and grab it from here I'm going to assume that we need an API key and an endpoint the next thing we're going to need is the speech SDK audio config well actually um we're actually going to need our speech SDK speech config and by the way if you're watching this you can just find this in the repo and pull it from there in the Azure examples because it will be in here um at the end of this video right now I'm just bringing it in here so here it wants an API key so we're just say API key okay and then this will just be our config and then the next thing we need is our audio output config one other thing we might have to specify here is the region so I go here and do that as well and I believe we're running everything in West us hopefully that's the correct word order sometimes it's the other way so that's part one the next thing is going to be the audio config so we have speech config just to make this less confusing and have one called Speech config here and then audio config so we'll set that up there um the next thing we need to do is we need to set up um The Voice we're going to use and so I go down here and what this is going to do is going to configure us to use the US available multilingual neural so when you're dealing with like synthetic voices uh there'll be there's like a model called neuro and those usually means that they're really really good that's the best description that I can give to it um I remember this when I was working with ad bus's um artificial voices they had like different grades of them and neural is one of the best ones it's probably just the way that the voice is generated the next thing we're going to need is the synthesizer so we'll go ahead and paste that in next here and here we are feeding in our audio configure and our speech configure to get our synthesizer all right and so now if we wanted to get text from um from here well I guess like you could put input here but I'm just going to put some text here I'm just going to say um this is what we want it to be be spoken but we'll say Star Trek is still the best SciFi TV show okay so that is my text that I want to be turned into speech and then the idea is that we're going to feed this text um to the synthesizer it's going to Output those results okay and so the next thing here is we need to make sense of those results so here we are going to look at the result I'm just going to shorten this I don't like how long that name is I'll just say results here it's really just results but that's fine so say if the result. reason equals that it's completed then we're going to go ahead and print out that it's been completed again if you need to pause and write this out go write this out normally I write this out from scratch but you know unfortunately uh it just was not easy for us to Source stuff here and pull from stuff okay so from here if it is cancelled I'm just going to update this so that this is like that if it's cancelled then we're going to print out that it's been canceled and if there is an error because it's been canceled we're going to want to know why that is so I'm just carefully going through here putting those details in okay and we're giving some reasons as to why so one question I have is where is it outputting this speech right because I'm looking at this code and I don't see it being saved anywhere and we're going to want to hear it right so that's something that I'm I'm kind of interested in but uh we can go on to the next line and maybe we can just print what the results are and we can figure it out from there so it's not asking for an endpoint per se but I would expect that it would need one otherwise how would it know to work but I guess the end points are pretty much the same so like if we go back over to here and um we look at its endpoint it's cognitive microsoft.com and if we go into our actual unified API here it's going to be very similar the only difference here is that this one says speech to text text to speech which is neural but how's it going to know to use that if we're not providing that information so there is a link here which maybe might tell us how we can work with it this is probably like the rest way of working with it so I mean we could do it that way as well we did do that earlier when we used um if you remember when we did translator because we didn't have the most update the thing so we'll see if we can get this to work and if it doesn't we'll work it another way but one thing I don't see here is US outputting the file so maybe it's stored in here because we want actually hear it if it works right so we're here and I need an API key so I'm just going to give this a try and is West us here that's good and so we'll paste that in here and I'm going to run this and then we'll go here next we'll choose this next and I'm just hoping that it knows what endpoint to go to and so we go to text and so here's the moment of truth will this work and it did not work okay so it says unable to connect connection refused cannot connect to server socket no such file directory could not do that so just give me a moment I'll figure it out okay all right so let's see if we can get uh Claude to help us out here because I feel like this one's a little bit tricky um and so maybe we'll do some comparison here and just see what we're looking at here so just give me a moment I'm just going to get my screen set up all right so I kind of have them side by side here um the reason I'm using Cloud on it is because chat PT today is not working um but I happen to pay for multiple um of these assistants I usually don't need to leverage uh these too often for coding but maybe for this case it might help us out so first thing is that we did the speech SDK so that is correct here it has a key and region we are providing a key and region and we are supplying those there right so we did that uh the next thing they're doing is they are setting um a voice here they're using Jenny and we're just using the uh a Ava multilingual neuros so I don't think that really matters too much I don't think that's our problem the next thing we have here is speech synthesizer SDK okay and so we appear to have something similar key difference here is they setting the audio config To None we're saying use default speaker so maybe we could take that out maybe we don't even need that so I'm just going to take this out and just simplify it whoops not need this one and it's because our font is really large here so or least I think that's why so I'm going to go here and just switch this out to none okay then we'll go here delete this and then we have our text from here we are doing speech synthesizer speech text async okay and then down below we have something very similar so we have reason complete here it's saving the audio file which is actually what I wanted to do so that's really good that we have this so go ahead and place this in here and I do want to save it in place so I'm going to go ahead and grab this above here so that's good as well um I might just put it there just save myself some trouble and the rest looks good so we're not too far off but again maybe the issue is that we are using the unified API and that one that key won't work there because we're not specifying something I do not know but let's go and just run it from the top okay so go here oh you know what well we're not using the end point so it doesn't really matter right now and then we'll do this and then we'll do this and then we'll do this and then we'll do this and it really isn't a whole lot different but this time it worked no problem so the only thing we Chang is we took out the audio config to none so maybe that was our problem we'll go ahead and run this and it has an issue with result it's because it's not called result it's called results and so we'll run that like that ah okay so thank you Claude not exactly sure what was wrong other than it didn't like our audio config setting but we were we were able to use our thing so let's see if we can hear this I believe I have system sound so um up here it shows me that there's system sound here so we should be able to uh hear this on screen so I don't know if we can play it in here probably not so I'll have to download this first all right and uh I'm going to open this up start Tre is the still the best Sci-Fi TV show Star Trek is the still the best sci-fi is is still the I thought I it Star Trek is still the best Sci-Fi TV show Star Trek is the still the best Sci-Fi TV show star it doesn't sound right for some reason Star Trek is the still the best Sci-Fi TV show oh is still the best Star Trek TV show okay so that's okay I mean I got it slightly wrong but that is totally fine the next thing we'll need to do is we'll do speech toex so that one worked really well I might just go ahead and use um Sonet to generate that out because clearly it was um a bit of a challenge to find that code so I'm going to go ahead here and we'll make another one here this will be speech to text we'll drop this down speech to text and I'm going to go ahead here and just say um okay now I want to do uh speech to text and we'll let that generate out we'll give it a moment okay it's actually pretty quick so we're looking at a very similar setup um except this one actually does have an a config okay so we'll go over to this one and we're going to bring these two over here not sure if we really need both but we'll do that whoops going to go ahead and copy this and we'll paste here I wonder if we just copy the cells let's see can I just copy all these cells not easily well I guess I'll just copy it one by one so place that one in there there and then we have our Imports and then we have our keys and then we have this and this is where it's going to vary because here we're going to bring back the audio config but the key difference here is we're going to say use default microphone I'm not sure how this is going to work because then it sounds like it's going to need me to speak into my microphone and I'm not sure how that would work uh we need a speech recognizer so we'll go uh to this one here and grab it here um I'm noticing that we did not specify um we do need to specify the language so that's something that's here that I'll have to bring over but we did not have to specify what it's using to synthesize the voice because I guess it's not synthesizing a voice that kind of makes sense I'm going to bring this here whoops and we'll bring this one down and so we want to bring this one over we still need this I believe actually no it's not this is a speech synthesizer and we need a speech recognizer so it looks very similar okay but this one is recognizer recognizer okay so we'll clear that out there we'll add another one here so speaking to the microphone and so I'm not exactly sure how that's going to work because we are in a jupyter notebook I'm not sure how it's going to request that information and then the last part here is just the outputs again if you're watching this you can just um get it from the Azure examples repo okay and that'll make your life a lot easier so I don't know this is going to work because I'm not sure how we feed it into here but let's go ahead and try it worst case maybe I can get an audio clip and then upload it but we'll see what happens here okay and unexpected keyword use Microsoft M microphone default um so go going back to here I'm just going to copy this line just so that we know if it's the same or not ah and so there is a difference this one says output config this one's audio config so maybe the other one failed because there was a a slight change in syntax or something I'm not sure so far okay and we now have this issue okay so I'm GNA see if we can just if we can change this and it says I'm out of messages till 3M and uh it's 253 right here and I kind of want I kind of want Cloud uh claud's help here so I'm going to pause the video I'm going to be here when I can get a little bit more help from our our uh generative AI I assistant here um because I'm not sure how we're going to do this one because it's giving us issues every time we do the audio input here okay so be back in just a moment all right so um I asked Claude and it's basically saying yeah you have microphone issues and uh we're going to see if it will provide us another way of doing this so um we can change this to pass it an audio file as opposed to using the microphone which is giving us trouble so what we'll do is go all the way to the top here and try this again now we might still have an issue here just because um but here it it's suggesting something very similar but here we're passing in a file name for an audio file right and I'm just going to go here and say path to audio file and we'll just assume this is the same place um I guess I'll go ahead and create an audio file so just give me a moment I'm going to go and um see if I can get some kind of audio file for us so just a moment well you know what I'm thinking we have this output file why can't we just use that right um so I'm going to actually do that and use our output wave now it's obviously not human speech it's generated speech but I would expect it to work very similarly um so that is pretty clear and it doesn't look like anything else has to change it's literally just those two lines so let's go ahead and run this one and then run the audio config and then choose the US language and then try this again and so now we're not having a problem with which suggests to me that maybe it's um it's in better shape here I'm just going to double check this line here this seems to be the same so go ahead and place that there no problem good and then we'll output our thing it says tar Trek is the is still the best sci-fi show ever and because it is a synthetic voice maybe if I had spoken into it or recorded one I would do that the only thing I think I'd have to do is stop this video I don't feel like U doing video editing after this so that's why we're using audio one there so those are two things we can do I feel like there's one more thing that we can do which is probably translation um so let me just take a look here so we have speech to text text to speech speeech translation intent recognition um so let's take a look here what's this an intent is something the user wants to do okay speaker recognition keyword recognition so lots of stuff here but maybe uh Speech transl would be interesting so let's go read about this for a second because i' imagine this is going to take text from one and another it's not going to sound the same but let me just read this for two seconds okay so here what it's suggesting is uh it will take a the speech service will uh take an audio stream in your specified source and have it translated into the output text in the specified language okay um so again I'm just going to leverage CLA here and just say oh okay now let's do um speech uh translation so an English audio source to Japanese if it can't do Japanese then Spanish please okay and we'll see if we can generate that out for us again I usually do not rely on uh Claud but again the uh it's very hard to find the stuff that we want to find here and so here we'll make a new notebook and this one's going to be speech translation we'll choose the kernel to be the same as for usual for usual here rename this speech translation and we're looking at something very similar so go over here and grab similar stuff so we're going to need this and then we're going to need this and we're going to need this and we're going to need what else here we have a translation config so this is a little bit different okay so I'll put our API key here and our region here um and then and we have a source so from a language um so the from language they put it down here as a function but we're going to go here and add this here now I don't really want a fallback I it was just more like if it wasn't available so I was asking like not to make it a fall back but to code it in if that was the case so I'm going to just change this a bit so that it is um we're not going to deal with a a fallback language i' rather do just Japanese directly here um and so then the idea is that we add our uh target language here again just copy and pasting these as we go here and you could write this in or get it from the code base wherever it is then they have a fall back there which we're going to ignore the next thing is we want to supply our audio file and this is just going to be output just keep sticking with that and then keeps going here but then we have the creating the translator okay and then we have a big dump of stuff here and so that looks pretty good to me um so I think I might just go back to our text of speech and just change this because I don't really like uh this text here so delete this here I'm going to put something that I know I'll understand in Japanese so uh we'll say um I am eating uh Ramen how about that I eating Ramen or how about I eating sushi okay so that should be something like sushi tab I think so we'll go to the top here and I'm going to go ahead and just execute everything we're going to restart it all and the idea is I want that to Output that text okay and there it is so I'm going to download this and then we'll play it here make sure that it is what we think it is I am eating sushi thanks sounds good very interesting intonation on that voice uh it sounded pretty good um but anyway let's go over to our speech translation and hopefully this will work so we're on the first one we'll run the second one this here the translator config the from language the two language the audio file the only thing that's wrong here is this so this I'm going to re-update this and then run this again and then run this one and it looks like it worked so we'll output it and uh result is not defined um good point oh you know what it is I think I'm missing a line here so after this line supposed to have this there we go and now we can run this and we have o That's the honorific O I'm gonna assume that's sushi sushi doesn't look like sushi is that Sushi let's go find out it's going to go over to Japanese dictionary is that Sushi oh it's sushi okay so we have o sushio tab Tha Mas Tabet Tha Mass I thought it' be tab tab but uh I mean I guess that also is the more plighter version of it but that worked exactly as we expected there's more that we can do with this um uh uh Speech API let me just see if there's anything else that I'd like to do here I might have made notes Here in um in our platform um no no that's it so we'll call this done I'm going to go ahead and just clear out these values here as per usual and we had a little bit we had to work around but it wasn't too bad so we go here go here and then go here clear this out and I'm just going to go ahead and clear the outputs restart and clear the outputs and then go to this one restart includ the outputs and then go to this one and restart includ the out puts I'm going to go ahead and download these three okay and then we are going to go over to our uh Azure examples repo I'm going to hit period here whoops period and then we'll make a new folder here called Speech so this is all kind of under Azure AI Services I kind of feel like I should have probably done that but whatever and so we'll just drop those in there there we go and so now if you need to follow along here we have the speech API okay there you go uh remember to shut down your compute and I will see you in the next one ciao hey this is Andre Brown in this video we're going to take a look at Azure AI video indexer which allows you to get U insights into analyzing your videos and audio content um so let's get to it I'm in the Azure portal we're going to go all the way to the top here and type in Azure AI video indexer okay so it's going to bring us over to here and as per usual we'll go ahead and create ourselves a new resource um I'm going to create a new Resource Group here calling this one a uh video indexer maybe AI video indexer and I'll just put some numbers ah it doesn't matter because I don't have a resource Group name that I was thinking it was the resource name and that had to be unique but I'm going to go ahead and type in AI video uh indexer now I don't know if it allows for hypens but I'm not even going to try I'm just going to go and do it that way I don't think the region here really matters I've been doing a lot of the um AI services in US West um but we'll stick with East us here um says connect all content from an existing classic account that is not the case storage for the allocated account so I'm going to have to create myself a new um uh storage account and we'll go ahead and call this AI video indexer so that we have somewhere uh to place our data and we'll go ahead and do this of course we can't do hyphen so we'll do this again and I'll just put some random numbers here on the end we'll go ahead and hit okay and so that looks good so far um then we have down below unlock generative eye connect your Azure video index or resources to Azure opening eye for more capabilities that sounds pretty cool um I kind of feel like doing that I'm not sure what we're going to get out get by doing that but maybe that's not a bad idea so let's make our way over um to open Ai and we might not discover anything interesting but we'll go ahead and create that and um so this is where it gets kind of tricky because we need that before we can go ahead and do that so what I'm going to do I call this one AI I'm going to just kill this tab here because that's no good leave we'll call this one ai ai video indexer and we'll leave that in eastus and so this will be uh open AI video indexer we're going to choose the standard tier as I don't believe there is any other tier right now we're going to leave Network completely open and we'll go ahead and create the Azure openi resource okay so this should create pretty quick but we will wait for this to complete so that resource is now created I do also want to point out that Microsoft has Azure AI video indexer and so we might look at this in a separate video um it's hard to say which one uh Azure wants us to look at and it is confusing when they have multiple offers so we will have to probably look at both of them so let's go ahead and uh go back to Azure AI video indexer here and let's go ahead and create our Azure AI video indexer we'll drop this down here and go to here and we'll say AI video indexer I'll put some numbers here just to make it happy East US is fine we're going to create one I'm going to try to stick with the same numbers here so it's less confusing um and so I'm just going to go here and take out the hyphens it hates hyphens it hates them and that seems fine that is good I'm going to go ahead and connect our open AI here we have system assign user assign we'll stick with system assign that seems fine to me not that I can ever remember Azure permissions no matter how much Azure I use and so here it has I have the rights to um contents degree to handle this stuff I absolutely do we'll go ahead and hit create I have lots of video content and if you want to use one of my videos you can absolutely do that I'm going to try to find one where I'm in a video with somebody maybe with um aish uh our security friend here but we'll wait for this to deploy and then I guess we'll have to upload something all right so our resource has now been created let's go ahead and uh visit it and so we have the portal and so that makes me think that you know if we signed up for that free trial I bet it would give us probably a very similar experience uh we also have the video indexer API so we could work with it programmatically um this account needs a manage identity role assigned to it assign assignment to connect to it so assign a rle sounds good to me and if they can also sign roles here that'd be really nice the less work I have to do the more happy I'm going to be awesome that was a really nice user experience uh so let's go ahead and explore the portal I we'll give that a moment to load all right so we have a few options we have Microsoft entra ID personal Microsoft account or Google um I'm going to go with Microsoft entra ID forly known as Azure ad which by the way Microsoft I think it could have kept with the original name it was a lot better and so now we are in here uh and so we can upload a video so I need some kind of video to upload here and it looks like we can also enter URL so if we could provide a URL um uh to YouTube that would be very interesting I'm not 100% certain if it can accept it but let's learn a bit more about uploading videos so what I want to know is can we provide it a link to YouTube you can't use URLs from streaming services such as YouTube that's probably the first thing that people are are thinking of um so what I'm going to do is I'm going to go find a video so just give me a second I'll be back in just a moment all right so I couldn't exactly find uh the video I was looking for but that's totally fine we we'll just go use this one and so if you ever want to download something from YouTube it's a little bit sketchy we're going to type in YouTube download video okay and the reason this is a bit sketchy is that you can end up with malware so be very very careful maybe just watch me do it and see what happens first before you do it yourself um but I think this is the site I normally use if I need to download videos so I'm to go ahead here and and be very very careful again just watch me do it before you do it yourself it says uh download the video and um I almost kind of wonder if I could just download this video and then um you know what maybe what I'll do is I'll just download the video myself can I download that no we don't need to install the app let's download plus enjoy your free tube ads in the background not now so I'm pretty C certain I can download this from my YouTu studio so what I'm going to do is download it and then upload it so that you can just get it from the GitHub okay so just give me one moment all right so I've downloaded it I'm going to go over to our GitHub account and this one is at Azure examples we are working on um uh video indexer so I'm just going to open this up here and we will just wait a moment here we'll open this up we'll say Azure AI video indexer or we'll say AI video indexer and so now I can go ahead and drag this video I'm just going to rename the video video to video I'm doing this off screen by the way yep so I've renamed it and then I'm just going to upload it here um I have to name it video example I already have a video name vide so I'm just name this video example here then I'm going to drag it on over here okay so now you have a means to uh utilize this video as well so you don't have to worry about trying to find a video so I'll just say uh add example video okay so we'll go ahead and commit that I'm going to make my way back over to here and so now it's suggesting that I can um upload a video so go here and say upload it says drag and drop so let's go ahead and drag and drop that looks good to me we'll keep it private um single bit rate sounds fine to me I mean it's not a streaming video but we'll leave it as single bit rate which is fine uh we have English down below that is correct and we'll go ahead and hit review and upload um that we can use that I use any let's read this by checking this box I certify that the use of any facial recognition functionality in the service is not by or for Police Department the United States wow that's an intense thing to say we'll go ahead and hit upload index so again if you don't want to upload yourself or you're worried about that you can just use me okay and so that's going to upload we'll just give that a moment uh to work okay there we go after a little wait there um uh we have our video uploaded so let's go ahead and click into it and just understand that we are on a trial account so there are some limitations that we can do but you can see that it's already extracting out information so right away it's detecting that there's a couch and there yes there is indeed a couch in the background ground um and as we go through here I'm just wondering if it's going to change things uh nothing super interesting here we have some topics so put corsera I'm not on corsera and I'm not on Udacity but it is correct about the educational component there so um technology computers pretty close I'd say that is um uh interesting there okay and and I think the the bar is indicating as to where it's finding that information or it's where it's assing that audio effect silence um there is no effect per se but it is silence so that is fair keywords here is certification extracted and your brown so that is nice has a human face that is true that is a human glasses microphone person clothing named entity so detected that it is angre brown um I'm not sure if it detected that because I said my name or if it because it could match me up to something says um I'm pretty joyous over here and I I guess so um but yeah there is some information we can go over to the timeline we have transcriptions we have the view um over here yeah this is the caption here but looks like we could uh see more information if we want okay so I go here and we say speaker and again just flipping around to see what kind of other information we can get so here we have key frames key frames we have labels so showing us when it determin those labels so we can go to storyboard and we get uh we just put all them on so you get kind of a rich uh Rich idea of information isn't that great I don't know I guess it's okay let's go ahead and hit edit and see what we have so it looks like we could modify that information after the fact and then we can download this data um into a format so pretty straightforward um I'm not sure if there's really much else to show in here but um create a custom speech model so uh information will be found so yeah that's interesting but just give me just a moment let me just see if there's anything else that be interesting for us to do while we are in here so yeah there could be other things that we could do in here but there's nothing that is um particularly interesting so I think that uh we can just call this done and uh we kind of saw the results of it similar to a service like Amazon recognition if you've ever used it but this clearly has a few more capabilities um but uh yeah uh that seems fine to me so let's go ahead and um get rid of this so I'm going to go to count settings go ahead and delete this account and we're going to say delete Andrew delete this account and it says delete pending this account will be permanently deleted in 90 days of course of course it's going to be in 90 days why would it be anytime sooner so I'm going to go back over to here and um I want to go ahead and delete this so hopefully we can tear this down and I'm going to go ahead and grab this and paste this in here and we'll say delete and I'm just going to confirm this delete just because this other one kind of indicated that it's not going to go away right away but uh yeah it looks like you can get into that service either through the Azure portal or as we saw uh you could just type in Azure AI video indexer and then um not have to use uh Microsoft Azure but of course that's the way we want to use it is is via Microsoft Azure this refresh here and it did not get rid of this did it tell us why oh it's still deleting it so we'll just wait a little bit here okay great so that appears all cleaned up uh and we are in good shape here uh so I'll see you in the next one ciao aure AI content safety is an API that detects harmful user generated and AI generated content in apps and services it includes text and image apis that allow you to detect material that is harmful it's great for Regulatory Compliance for obvious reasons because you can Main maintain a safe and appropriate user environment use cases include generative AI services online marketplaces gaming companies social messaging platforms Enterprise media companies K12 education Solutions and so we will programmatically work with the Azure AI content uh content safety API um and then we'll also talk about the studio which um is going to give us a more userfriendly environment Azure AI content safety studio is a gooey for the Azure AI content safety API and you're probably starting to notice a trend with um these Azure AI services that they'll have an API and then a studio so it handles offensive risky or undesirable content using Advanced content moderation ml models provides templates and customized workflows to build your own content moderation system and now this thing is located with an Azure eii studio um previously it was not inside of um Azure Studio but they're starting to roll everything into this Azure Studio even at this time is considered preview but it seems like with all the work that they been but putting behind it it's going to become GA at some point um so that's kind of interesting uh the key features here are out of the boox AI models includes pre-train models and Microsoft built-in block list for flagging profanities custom block list allows users to upload their own block list for specific use cases content upload users can upload their content or use provided sample content to test the system there are three main things they want you to know about moderate text content moderate image content and monitor online activity so um we don't do a whole lot for labs with this because I think the programmatic way is a lot more valuable but we do look at it and it's pretty straightforward so I just want to go over these three main features with some screenshots so you have an idea of their capabilities so we can meet uh the requirements for the exam so let's talk about text moderation um this provides an efficient and customizable way to manage harmful text content in your applications no surprise there um so we have an interface where you can test content from single sentences to entire data sets assess results directly in the portal for immediate feedback uh customize sensitivity so adjust the levels and fine-tune the content filters manage block lists to meet your specific moderation needs um we can export code to implement the moderation tool in your apps save time and simplify your workflows with easy integration and you know we're looking at three things but there's a lot more models than just these three but uh these are the three again we want to focus on let's talk about image moderation so as you can imagine it's for ensuring your images comply with content standards so you guess it you can upload images um do it right in the portal you have customizable sensitivity that you can uh do that and you can obviously integrate it into your apps right now let's talk about monitor online activity this one's a lot more boring but uh we got a bunch of text here we got to get through monitor online activity provides a comprehensive overview of your content moderation performance enabling you to track API usage and Trends across different content types um for the type of information we can collect it has detailed metrics such as categories and severity of distribution monitor latency errors and blockless detections um for performance we get a full picture of the content moderate moderation performance we can optimize workflows based on detailed insights it has a userfriendly interface as per usual I do not have a screenshot here today um we have performance tracking tools as well so nothing super exciting there but again I think that the programmatic part is a lot more important so we're going to spend more time on that we will look at content um the content safety studio and it's very easy to play around with so you're going to be able to figure it out pretty easily okay hey this is Angie Brown we're going to take a look at content safety studio and so if you were to go up here and type in content safety it's going to bring you under Azure AI Services I do also want to point out if you typed in um content safety studio um in here it would also bring you to content safety cognitive azure.com where looks like you could run resources here doesn't indicate as to what and also within the Azure AI Studio it appears under here as well where we we can go in and play around with it um but what I want to do is use it the pratic uh programmatic way because this is going to be the way that we're probably going to want to utilize it so let's go ahead and set this up I'm going to put this under AI managed workloads and this is going to be in West us because I'm doing everything over there I call this content safety uh example exp just put some numbers here and we have some price tiering I'm going to go with the free tier well let me just take a look here because maybe the free tier is going to severely limit us so go to the pricing table and so the difference here is with free we get uh these four um so it looks like we can do everything with the free one so let's go ahead and use the free one then so we'll go ahead and do that review and create okay we'll create that resource and so we'll just wait for that to deploy okay it is deployed let's go to that resource now and so it says congratulations you're ready now explore the quick start guidance to set up and get set up and running content safety um okay where is the quick start so maybe here on the left hand side we might have quick start somewhere usually quick start is appears on the overview I mean maybe this is the quick start because it's it's listening that as such but anyway we got to get the API keys to authenticate to your apps make API calls enjoy coding so I guess what I'll do because this all going to be API driven I'm going to go back over to here I'm going to start this up and we are going to get this working and once this is running we'll go ahead and grab some keys and get to it okay let's take a look and see if our compute is ready there it is going to go ahead and launch this up in Jupiter labs and so we are going to need ourselves uh an API key so I imagine we're just going to go over to manage API Keys here and I guess we'll end up grabbing that one here it would have been really nice if we had a quick start so we could just get to it but they don't appear to have one I'll go over the documentation maybe they have something there well it says quick start over here so I guess that is a good start um I mean that's one place where we can work with the content safety Studio sure but I'm looking for how we can interact with it programmatically we'll go over to here and maybe we'll have analyze text image and so yeah looks like we have some content safety stuff in here so maybe I can work with this as the basis so we'll just say build that doesn't matter here and we're going to go back a step and we're going to make a new folder here and call it content safety okay and um we will make well I don't need a folder well I guess we'll have in a folder that's fine and we'll make a new one here we'll say new file or new notebook and we'll rename this it'll be content safety um I'll just do SDK name this again sorry content safety and I'm going to see maybe they have a read me here sometimes they have them at the top level here yeah so this what I was looking for so I'm going to go ahead and try to install this way we'll do percentage pip like that and we'll run that we are going to need um our key and our endpoint probably so if we just I'll grab this link here just in case you're looking for it convert that to markdown say resources and we'll go back over to here so it looks like we're going to need our API key and our point so I'm going to go ahead and just say API key and endpoint we'll go back over to here and this is our end point so I'm going to paste that in here as such and then we'll go back and get our actual key and I would love to load this via nbar but uh again not the best at figuring that out so we will run this so those two are set we'll go back over to our example here and we have these two so I'm going to go ahead and grab this I'll just grab all this big block here and so we have Azure key credentials which is here uh content safety client block Client List um so we have our endpoint I'm just going to clear this on out and then we have our API key so this will be API key and so in theory that should work uh so I'll go ahead and run that and see what happens no problem so far so here it has content safety client content safety block um I mean depends on what this is doing right so this is for making a blockless client is that even what I want to do um so let me just read this for a second okay I just hopped in one of these examples I don't think we really need to um have a block list I think that's a particular feature that we can uh set up uh so I mean this is probably fine let me go back here and try this again so this is probably fine but I'm hoping that uh you know we get this working very easily so we have content safety text category so this is something else we're going to want here I'm just going to grab this whole block here and we'll go back to our Imports and I'm just going to place that here I'm going to grab this move it here so now we have those there so we already created a client you are an idiot I was hoping that it would give me some kind of text that I could use because I didn't want to have anything that would be too offensive and then we have our analysis there here down below so we'll copy that and I'll add this here as such so we'll go here and then run this and then run our request and so I think this is all of the code so I want this part for sure okay and I'm just going to fix this indentation here I don't need this because we're not calling this as a function and so the idea is that this should return results for us and so we'll run it and it doesn't know what client is fair enough as this is called this here so I'll go ahead and just switch that out like that and there we go so that's how we can do our text content analysis so I'm going to go over sorry there and not sure what happened to my throat there but um I'm going to go over here and just change this to be very specific spefic this is uh text analysis so I'm going to rename this I think I might have to get some water Analyze This will be analyze text and so we'll do that one and we'll just keep going through this I'm going to get some water be back in just a moment all right so let's continue on so we have uh completed analyze text um there's going to be probably some other ones that we can do so let's go take a look at some other examples so sample analyze analyze image that would be a really good one to do so let's see if we can do that and we'll make a new notebook here this one we'll use um the SDK kernel here and we're just going to rename this this will be analyze image so some of this is going to be still applicable so if we go back to this one here um I imagine we'll do still do this and these are going to be the same and this one's probably going to be similar but there might be some differences yeah I'll just grab this one here the big one and we'll fix that indentation um um I want to go here and add this so that is our client I'll just grab it from this one here and then we'll add another so here we can see we are opening an image you'll have to provide it an image file so it'll have to watch out for that which apparently uh appears to be here so I'm going to go and just add this um underneath here and I think I spelled this wrong over here it's kind of bugging me lies there we go so because this would get its current path like where we exactly are sorry and maybe we would just grab the image in place from here I'm curious as to what image they're using here but we'll check here in just a moment we go up maybe here sample data so we have this very offensive image how dare they um I'm going to upload here I'm just going to pause I'm not exposing my entire screen but I'm just going to go ahead and upload there there we go I just uh got the image and here it is there so I'm thinking that that should work this is going to try to go up a directory we do not need to go anywhere but the current location so that should be what we need to get that image path um going back over to this code here actually just right here then after that we have our results so I'll add this here take this off on the end okay and so we can go now run the rest and hopefully this just works it might not it's not a big deal if it doesn't we'll just fix it and I'm not sure what we would do here just give me a moment so I'm going to give this a go I'm not sure if this is going to work but um I'm going to go back over to here and try this actually before we do that I'm just going to go comment this out I just want to see see what happens if I uh take this up here I'll need to insert this way above this is where I'd like to place it right up here I know we have import statements down here as well I'm just going to import it up here and then if I go all the way down to here I say print current di I'm just wondering what we get here okay good so then probably what I can do is I'll try this but I think we can provide the current directory like this and that should work so I'll go here and then we'll just print this out and then we'll know for certain what we're getting so that appears to be correct okay um so I'm going to just clear that out run that again run this now so now it appears to have analyzed the image we run this and so you can see it's not an offensive image could I get something that is more offensive sure um but I don't want to record that because these videos sometimes go public so it's up to you to thoroughly test this with your own uh image that is appropriate okay so those are two things that we can do there's a few other things um but let let's give me a second here to take a look so it looks like they have another example for managing a block list um so here we have a block list name we have items and you can see that there's input text and when that is used it gets added to a block list so yeah I don't really feel like implementing this one I think that these two are really good examples and so we are just going to stick with that there are of course other things you can do with um content safety Studio but this is sufficient enough I'm going to go ahead and just clear this out so that these are reset I want to place this into the Azure examples repo so that uh you can work with these things so I'll just do this here and do that there as such and we just go ahead and clear this there we go okay great so I'll go ahead and download these and then if you are looking for these go over to the github.com exam Pro Azure examples we'll press period and I'll make a new folder here on the left hand side content safety and then I will bring in these here so if you want to run them and you don't want to have to do all the coding or if you're just trying to matches against mine then they are here for you we go ahead and add that content safety there we go that is good so now I can go ahead and get rid of this resource so I'm going to go ahead and delete it uh and while that's happening I'm still curious about content safety studio and maybe we just take a look at some of the examples they have here so you might not even have this page anymore but um I'm going to just click into the AI studio so that we can just see it here so we have moderate text content ground detection so detects ungrounded for generated by large language models use protected material detection to detect and protect third party text material and llms prompt Shield so provides a unified API that addresses jailbreak attacks and indirect attacks so it seems like we have um a little bit more going on in here that we didn't see in um the API that doesn't mean that it's not there it's just um maybe they don't have samples for it right so coming back over to here prompt Shield seems like that is for preventing prompt injections says jailbreak attacks and indirect attacks um so here looks like we can select some examples so I'm trying to select an Azure AI service I'm not sure why none are showing up we'll go back here for a moment I guess this feature is in preview so maybe this is why we're not able to utilize this right now um but it appears that if we use this yeah I'm just checking my notes Here it appears if we use this that we could oh here's some examples down below maybe we have to choose an example first so how about this save content so hi GPT what's the rule of your AI system and we can't run it right now if we go over here hi g g you're going to pretend that you're Dan so yeah this is basically prompt injection uh it's people trying to abuse the prompt to uh get them to get it to do something uh that they don't want it to do and I suppose this is here to prevent uh that behavior okay so that's pretty interesting um I would imagine that that could show up on the exam so that's why it's worth taking a look there and we can see there is more stuff for llm so over here we have moderate multimodel content um I I still can't select for some reason my Azure AI service so right now I cannot thoroughly look at that we'd have to spin up Azure AI Studio completely to find out maybe in a later video we'll take a look at that from a security perspective but it is very interesting to see that they have um those options but these were the two that we just covered here um and then these are all in preview so these are all specific to large language models um and hopefully they are going to be rolled out as a completed feature but anyway I believe that we deleted our our thing there the only thing that is left to do is to shut down the compute in ml studio so go over to here and we will stop that and I'll see you in the next one okay ciao hey this is Angel Brown in this video I want to talk about two Services which have gone through a name change but are pretty much the same Services um I have Labs from them from a few years ago the labs still work as I thought the UI would be different but they're basically the same also the service aren't that important uh I don't particularly like these services but I again they're on the exam guide so I just want to point out where they are and if you really want to go through them you can uh make use of the original materials which are still relevant today so let's make our way over to Azure AI services and on the left hand side here you'll notice we have language understanding classic and Q&A maker classic so I just want to show you how similar they are to the old ones I'm going to go ahead and open these up here okay and um I'm also going to show you where the new one is which will be under language services so what I'll do here is we'll start with this one language Services going to go ahead and hit create and just select this one because this is going to also add Azure AI search which we apparently need now and I'll just call make a new a group just say Lang you new and I'm just going to say Lang you new and choose the pricing tier here this is going to spin up Azure AI search if you have another one it will conflict but we have one here I'm going to checkbox this down below we'll hit review and create and we'll let that get going while that is weighing I'm going to go ahead and create language understanding or also known as Lewis notice is saying it's being retired 2025 there's a new version that's fine if you can't create it it's the future I just again just trying to show you where this is so Lewis old right in the future this might again might not be available so really what oh we probably can't start with ls old Lewis my old service name the resource your resource can only include alphab numeric characters okay and it won't even let me do it so you know I was thinking what I could do is show you the old one be like hey it's the same experience but it's it's not going to let me do that here today so we'll go ahead and just ignore that I'm going to create this uh one here all right so that deployment is complete let's go ahead in here and go into the language service so over here we have language studio and this is where uh the replacement or the reshuffling of um those two services are so we'll go ahead here just choose the language resource here and if you go here to understanding question and conversation language you'll see down below here next generation of Q&A maker next gener generation of Lewis so the information from before is still relevant because if you open up I think these go to the same place let's take a look here so we open up this one uh yeah language Studio hold on just click back here for a moment click here yeah they're both going to end up opening a new project okay I'm just going to choose English we'll hit next Lang you example and again I'm not going to go ahead and and make something uh make much here because I've done this before and this service frustrates me to no end the key difference here is that they've answer they've added asure search and um it integrates with open AI but I can't get it to work consistently um but yeah it's in here and so the idea is you create a project and you know we could add source files we could do chitchat whatever we want give this a moment here but up here we did question and answering I think if we were to create another project um the other way let me just go up here for a moment let's go into this one yeah it's it's the whole same UI okay I think if you uh go ahead and create a Lewis project see these are completely separate say my this project we hit next yeah so it's a little bit different where you add your intent so here it' be like book flight and you the difference of of Q&A Q&A is very much um it's like if then else whereas the the uh Lewis language understanding it's it's actually a um an llm model where you're giving information and you train the you train the model and so it is um it is like a much more cost effective uh version of um utilizing a a large language model so again I have the older Labs go watch the older Labs I just needed to show you how to get to these two Services uh the differences in the UI are very minor um with exception that this one now inte integrates Azure AI search which makes sense there so I'm going to go ahead and spin down this resource you will want to keep it up if you want to go ahead and do these I personally again do not like these services and they don't appear that much on the exam so I'm just going to um admit them here today okay and I will see you in the next one all right ciao hey this is Andrew Brown from exam Pro and we are looking at natural uh understanding or or Louise it depends on how you like to say it and this is a no code ml service to build language natural language into Apps Bots and iot devices so quickly create Enterprise ready custom models that continuously improve so Lewis I'm going to just call Lewis because that's what I prefer is access via its own isolate domain at lewis. a and it utilizes NLP and nlu so NL use the ability to perform or ability to transform a linguistic statement to a representation that enables you to understand your users naturally and it is intended to focus on intention and extraction okay so where the users want or sorry what the users want and what the users are talking about so uh the ls application is composed of a schema and the schema is autogenerated for you when you use the Lewis AI web interface so you definitely aren going to be writing this by hand but it just helps to see what's kind of in there if you do have some programmatic skills you obviously you can make better use of the service than just the web interface but the schema defines intentions so what the users are asking for a app always contains a nonone intent we'll talk about why that is in a moment and entities what parts of the intent is used to determine the answer then you also have utterances so examples of the user input that includes intent and entities to train the ml model to match predictions against the real user input so an intent requires one or more example utterance for training and it is recommended to have 15 to 30 example utterances to explicitly train uh to ignore an utterance you use the nonone intent so intent classifies user utterances and entities extract data from utterances so hopefully that understands I always get the stuff mixed up it always takes me a bit of time to understand there is more than just these things there's like features and other things but you know for the AI 900 we don't need to go that deep okay uh just to get to visualizing this to make a bit easier so imagine we have this uh this utterance here these would be the identities so we have two in Toronto this is the example utterance and then the idea is that you'd have the intent and the intent and if you look at this keyword here this really helps where it says classify it's that's what it is it's a classification of this example utterance and that's how the ml model is going to learn okay hey this is Andrew Brown from exam Pro and we are looking at Q&A maker service and this is a cloud-based NLP service that allows you to create a natural conversational layer over your data so Q maker is hosted on its own isolate domain at q& maker. it will help the most uh it will help you find the most appropriate answer from any input from your custom knowledge base of information so you can commonly uh it's commonly used to build conversation clients which include social apps chat Bots speech enabled uh desktop applications uh Q&A maker doesn't store customer data all the customer data is stored in the region the customer deploys the the dependent Services instances within okay so let's look at some of the use cases for this so when you have static information you can use Q&A maker uh in your knowledge base of answers this knowledge base is customed to your needs which you've built with documents such as PDF and URLs when you want to provide the same answer to a repeat question command when different users submit the same question the answers is returned when you want to filter stack information based on meta information so metatag data is provide uh provides additional filtering options relevant to your client application users and information common meded information includes chitchat content type format content purpose content freshness and there's a use case when you want to manage a bot conversation that includes static information so your knowledge base takes uh takes a user conversational text or command and answers it if the answer is part of a predetermined conversation flow represented in the knowledge based with multiple TurnKey contexts the bot can easily provide this flow so Q&A maker Imports your content into a knowledge base of questions and answer Pairs and Q&A maker can build your knowledge base from an existing document manual or website you're all docx PDF I thought this was the coolest thing so you can just basically have anyone write a docx as long as it has a heading and a and text and I think it can even extract out images and it'll just turn it into uh the bot it just saves you so much time it's crazy it will use ml to extract the question and answer pairs the content of the question and answer pairs include all the alternate forms of the question metad dag tags used to filter choices during the search followup prompts to continue the search refinement uh refinement K maker stores answers text in markdown once your knowledge base is imported you can fine-tune the imported results by editing the question and answer pairs as seen here uh there is the chat box so you can converse with your Bot through a chat box I wouldn't say it's particularly a feature of Q&A maker but I just want you to know that's how you'd interact with it so when you're using the Q&A maker AI the Azure bot service the bot composer um or via channels you'll get an embeddable one you'll see this box where you can start typing in your questions and and get back the answers to test it here an example is a multi-term conversation so somebody asked a question a generic question and that said hey are you talking about idus or Azure which is kind of like a follow-up prompt and we'll talk about multi-turn here in a second but uh that's something I want you to know about okay so chitchat is a feature in Q&A maker that allows you to easily add pre-populated sets of top Chit Chats into your knowledge base the data set has about 100 scenarios of chitchat in voices of multiple personas so the idea is like if someone says something random like how are you doing what's the weather today things that your Bot wouldn't necessarily know it has like canned answers and it's going to be different based on how you want the response to be okay uh there's a concept of layered ranking so lay uh Q&A maker system is a layered ranking approach the data is stored in Azure search which also serves as the first ranking layer the top result for uh from Azure search are then passed through Q&A makers NLP reranking model to produce the final results and confidence score T touching on multi-turn conversation is a follow-up prompt and context to manage the multiple turns known as multi-turn for your Bot from one question to another when a question can't be answered in a single turn that is when you're using multi- turn conversation so Q&A maker provides multi-term prompts and active learning to help you improve your questions based on key and answer Pairs and it gives you the opportunity to connect questions and answer pairs the connection allows the client application to provide a top answer and provide more questions to refine the search for a final answer after the knowledge base receives questions from users at the publish endpoint cre maker applies active learning to these rule work questions to suggest changes to your knowledge base to improve the quality all right all right so now we're on to Q&A maker and so we're not going to need to do anything pratically because Q&A maker is all about no code or L code to build out a questions and answers uh uh bot service so what we'll do is go all the way up here and I want you to type in Q andm maker. because as far as I'm aware of Sonic accessible through the portal sometimes you can find these things um again if we go to the marketplace I'm just curious I'm going just take a look here really quickly uh whenever it decides to log Us in here okay great so I'll go over to Marketplace and probably if we typed in Q&A maybe we do something here Q&A yeah so we go here um give it a second here seems like Azure is a a little bit slow right now usually varies fast but uh you know the service varies well it's not loading for me right now but that's okay because we're not going to do it that way anyway um so uh again go to Q&A maker. and what I want you to do is go all way to the top in the right corner and we'll hit sign in and what we'll be doing is connecting via our single sign on with our account so it already knows I have an account there I'm going to give it a moment here and I'm going to go ahead head and just give it a second there we go so it says I don't have any um knowledge bases which is true so let's go ahead and create ourselves a new knowledge base and here we have the option between stable and preview I'm going to stick with stable because I don't know what's in preview I'm pretty happy with uh that and so we need to connect uh Q&A Service uh Q&A service to our knowledge base and so back over here in Azure actually I guess we do have to make one now that I remember we actually have to create a Q&A maker service so I'll go down here and put this under my Cog Services we'll say my um Q&A Q&A service might complain about the name uh yep so I'll just put some numbers here we'll pick uh free teer sounds good so I'll go free when I actually get the option that's what I will choose um down below we'll choose free again us e sounds great to me uh it generates out the name it's the same name as here so that's fine uh we don't need app Insight but I'm going to leave it enabled because I think it changes it to standard or s0 when you uh do not um have it enabled unusually and so we will create our Q&A maker service give it a moment here and it says I remember it will say like even if you try it might have to wait 10 minutes for it to create the service so even though even after it's provisioned um it'll take some time so what we should do is prepare our doc because it can take in a variety of different files and I just want to show you here that uh the Q&A they have a whole paper here formatting the guidelines and basically it's pretty smart about knowing where headings and like answers is so for unstructured data we just have a heading and we have some text so let's write some things in here that we can think of since we're all about certification we should write some stuff here so how many adus certific are there I believe right now there are uh 11 uh adus certifications okay and maybe if we use our headings here this would probably be a good idea here y okay another one could be um how many fundamental azure certifications are there and uh we'll give this a heading we'll say um there are three Azure I think there's three there's other ones right like Power Platform stuff but just being Azure specific there are three Azure fundamental certifications certification so we have um the dp900 the AI 900 the a900 I guess there's four there's the sc900 right so there are four okay we'll say which is the hardest um Azure assoc Azure Association certification and uh what we'll say here is I think I mean it's my it's my opinion is it's the Azure administrator had some background noise there that's why I was a bit pausing there but the Azure administrator AZ 104 I would say that's the hardest uh which is harder um the uh adus or Azure certifications I would say uh Azure certifications are harder because they uh check uh exact steps for implementation where AWS focuses on Concepts okay so we have a bit of a um knowledge base here so I'll save it and assuming that this is ready because we need a little bit time to put this together we'll go back to QA get hit a refresh here give it a moment drop it down choose our service and uh notice here that we have chitchat extraction and only extraction we're going to do chitchat I will say uh my or this will be uh the reference be change any time this will be like uh uh certification Q&A and so here we want to populate so we'll go to files here I'm going to go to my desktop and here it is I'll open it we will choose professional tone go ahead and create that and so I'll see you back here in a moment all right so after waiting a short little time here it loaded in our data so you can see that it it figured out which is the question which is the answer and it also has a bunch of defaults so here if somebody was asked something very s uh silly like can you cry I'll say I don't have a body it has a lot of information pre-loaded for us which is really nice if we wanted to go ahead and test this we could go and say um we'll go here and then we'll write in uh we say like hello say boring it says good morning okay so we'll say um how many uh certifications are there we didn't say AWS but let's just see what happens and so it kind of inferred even though we didn't say AWS in particular so and notice that there's AWS and Azure so how many fundamental Azure certifications things like that and so it chose AWS so it's not like the perfect service but it's pretty good I wonder what would happen if we um placed in uh one that's like Azure I don't know how many Azure Sears there are we'll just say like there's 11 12 I can't never remember they're always adding more but uh it I want to close this here there we go so let's just go add a new key pair here and we'll say how many Azure certification are there I should have said certifications I'll probably just set one moment so they're there are 12 Azure certifications who knows how many they have they could have like 14 or some you could say like between 11 and 14 they just add them they just update them too frequently I can't keep track so uh we'll go here and we'll just say certifications and we will save and retrain so we'll just wait here a moment great and so now we'll go ahead and test this again so we'll say how many certifications are there and see it's pulling the first answer if I say uh azure if let see if it gets the right one here how many Azure certifications are there okay so you know uh maybe you'd have to say you'd have to have a generic one for that match so if we go back here and we say how many certifications are there you say uh you know like uh uh which certification uh uh which Ser cloud service provider here we got ads Azure uh follow prompt you can use Guides Through conversational flow prompts are used to link Q&A Pairs and can be displayed um I haven't used this yet but I mean it sounds like something that's pretty good um because there is multi-turn in this so the idea is that if you had to go through multiple steps you could absolutely do that um we could try this a little bit here uh follow prompt you can use the guide use conver prompts are used to link Q&A pairs together texture button for suggested action oh okay so maybe we just do like AWS link to Q&A and then so search an existing Q&A or create a new one um so would say like how many adab US oh okay we're typing it in context only this follows up will not be understood out of the context flow sure because it should be within context right and uh here we can do another one we say like um Azure we'll say how many Azure context only oops it uh got away from me there we'll save that and uh what we'll do is save and train so we go back here and we'll say how many uh certifications are there enter so we have to choose AWS and so there we go so we got something that works pretty good there since I'm happy with it we can go ahead and go and publish that so we'll say publish and now that it's published we could use Postman or curl to uh trigger it what I want to do is create a bot because with Azure bot Services then we can actually utilize it um with other Integrations right it's a great way to uh um use your Bot or to actually host your Bot so we'll go over here it'll link it over uh if you don't click it it doesn't preload it in so it's kind of a pain if you lose it you have to go back there and click it again but uh let's just say um certification Q and A and we will look through here so all going to go with free premium messages 10K 1K premium message units messages I'm kind of confused by the pricing but F0 usually means free so that's what I'm going to go for that SDK or no JS I'm going to use no GS not that we're going to do anything there with it go ahead and create that and I don't think this takes too long we'll see here and just go ahead and click on that there I'll just wait here a bit I'll see you back here in a moment all right so after waiting I don't know about 5 minutes there it looks like our bot service is deployed we'll go to that resource there uh you can download the bot source code actually I never did this uh so I don't know what it looks like so be curious to see this um just to see what the code is I assume that because we CH chose nodejs it would give us um that as the default thing there so download your s code as your B creating the source zip not sure how long this takes might be regretting clicking on that but uh what we'll do is we'll go on the left hand side here to channels because I just want to show uh here yeah I don't not didn't download uh we'll try here in a second but um what we'll do is we'll go back po profile uh unspecified bot what are you talking about yeah maybe it needs some time H so you know maybe we'll just give the bot a little bit of time here I'm not sure why it's giving us a hard time because this bot is definitely deployed if we go over to our Bots right bot Services it is here sometimes there's like latency you know with uh Azure and oh there we go okay see it works now fine right and so I want to show you that there's different channels and these are just easy ways to integrate your in different services so whether you wanted to use it with Alexa group me Skype telepon twio Skype business apparently they don't have that anymore because I got sell teams now right uh keik which I don't know people still use that slack we should had Discord telegram Facebook email um that's kind of cool but teams teams is a really good one I use teams uh there's a direct line Channel I don't know what that means and there's web chat which is just having like an ined code so if we go over can go and test it over here just start test in our web chat and so it's the same thing as before but we just say things like uh um how many certifications are there Azure and get a clear answer back we will go back up to our overview let's try to see if we can download that code again I was kind of curious uh what that looks like if it will download must be a lot of code eh there we go so now we can hit download and so there is the code I'm going to go ahead and open that up uh so yeah I guess when we chose JavaScript that made a lot more sense let's give it a little Peak here I'm just going to uh drop this on my desktop here so let make a new folder here and call this uh bot code okay I know you can't see what I'm doing here but uh let's go here and drag double click into here and then just drag that code on in and then what we can do is open this up in VSS code I should have VSS code running somewhere around here just going to go ahead and open that I'm off screen here I'll just show you my screen in a moment say show code oops file open folder bot code okay and uh we'll come all the way back here and so we got a lot of code here never looked at this before but you know I'm a pretty good uh programmer so it's not too hard for me to understand um so looks like you got API request things like that I guess it would just be like if you needed to integrate into your application then it kind of shows you all the code code there I'm just trying to see our dialogue choices H nothing super exciting okay you know when I go and make the um was it the AI or the AI 100 whatever the data scientist course is I'm sure I'll be a lot more thorough here but I was just curious as to what that looks like now if we wanted to have an easy integration uh we can get an mben code for this so if we go back to our channels I believe uh we can go and it edit ah yes so here we have a code so what I'll do is go back to jupyter Labs I'm just going to go make a new empty um notebook so we'll just go up here and say notebook and this can be for our Q&A doesn't really matter what kernel uh we'll say Q and A maker just show like if you wanted a very very simple way of integrating your Bot um we would go back over to wherever it is here ah here we are I'm going to go ahead and copy this iframe I think it's percentage percentage HTML so it treats this cell as HTML and I don't have any HTML to render so we will place that in there and notice we have to replace our secret key so I will go back here and I will show my key and we will copy that and we will paste that key in here and then we'll run this and I can type in here where am I just ask silly things uh who are you how many Azure certifications are there well I wonder if I just leave the are there off let's see if it figures it out okay cool so uh yeah I mean that's pretty much it with Q&A maker uh um so yeah that's great so I think we're done here and we can move on to checking out Lewis or Luis learning understanding to make a more uh robust bot okay all right so we are on to our last cognitive service and this one is going to be uh Lewis or Louise depending on how you like to say it it's Luis which is language understanding so you type in luis. a uh and that's going to bring us up to this external website still part of um Azure just has its own domain and so here we'll choose our subscription and we have no author authoring source so I guess we'll have to go ahead and create one ourselves so go down here and we'll choose my cognitive Services Azure resource name so my o uh service or my cognitive service create create new cognitive service account but we already have one so I don't want to make another one right it should show up here right are valid in the author authoring region so it's possible that we're just in the incorrect region so we might end up creating two of these and that's totally fine I don't care it's as long as we get this working here because we're going to delete everything at the end anyway and so just say my Cog service 2 and uh we'll say West us because I think that maybe we didn't choose one of these regions let's go double check uh if we go back to our portal just the limitations of the service right so we'll go to my Cog Services here um I just want to go uh cognitive services so I just want to see where this is deployed and this is in um West us yes so I don't know why it's not shown up there but whatever if that's what it wants we'll give it what it wants okay shouldn't give us that much trouble but hey that's how it goes and so we have an author authoring service I'm going to refresh here and see if it added a second one it didn't so all right that's fine so we'll just say uh my sample bot um we'll use English as our culture if nothing shows up here don't worry you can choose it later on I remember the first time I did this it didn't show up and so now we have my Cog service my C custom vision service we want Cog service so um anyway it tells you about schema like how you make a scheme animates talking about like bot action intent and example utterance but we're just going to set up something very simple here so we're going to create our attent the one that we always see is uh flight booking so I'll go here and do that and what we want to do is write an under and so like uh book May a flight to Toronto okay and so if someone were to type that in then the idea is it would return back the intent this value and metadata around it and we could programmatically provide code right so what we need is identity uh identities and we can actually just click here and uh make one here so enter named identity we'll just call this location okay here we have an option machine learned and list if you flip between it this is like imagine you have a ticket order and you have these values that can uh change or you just have a value that always stays the same like list so that's our airport that makes sense we'll do that if we go over to ENT entities we can see it here all right so uh nothing super exciting there but what I want to show you is if we go ahead and um we should probably add fight booking should be uh how about book flight flight booking flight fight booking okay so we'll go ahead and I know there's only one but we'll go ahead and train our model because we don't need to know tons right we cover a lot in the lecture content uh to build a complex spot is more for the uh associate level um but now what we can do is go ahead and test this and we'll say book me a flight to Seattle okay and notice here it says book flight we can go inspect it and we get some additional data so top scoring so it says How likely that was the intent um okay so you get kind of an idea there there's additional things here it doesn't really matter um we'll go back here and we will go ahead and publish our model so we can put it into a production slot you can see we have sentiment analysis speech priming we don't care about either of those things we can go and see where our endpoint is and so now we have uh an endpoint that we can work with um so yeah I mean that's pretty much all you really need to learn about Lewis um but uh I think we're all done for cognitive services so we're going to keep around our our notebook because um we're going to still use our jupyter notebook for some other things but what I want you to do is make your way over to um your resource groups because if you've been pretty clean it's all within here we'll just take a look here so we have our Q&A all of our stuff here I'm just making sure it's all there and so I'm just going to go ahead and delete this Resource Group and that should wipe away everything okay for the cognitive Services part all right so we're all good here and I'm just going to go off and I'll leave this open because it's always a pain to get back to it and reopen it but let's make our way back to the home here in the Azure uh machine Learning Studio and now we can actually explore building up machine learning Pipelines hey this is Andrew Brown from exam Pro and we are looking at face service and Azure face service provides an AI algorithm that can detect recognize and analyze human faces and images uh such as a face in an image face with specific attributes face landmarks similar faces and the same face as a specific identity across a gallery of images so here is an example of an image uh that I ran that will do in the follow along and uh what it's done is it's drawn a bounding box around the image and there's this ID and this is a unique identifier uh string for each detected face in an image and these can be unique across the gallery which is really useful as well another cool thing you can do is a face landmarks so the idea is that you have a face and it can identify very particular components of it and up to 27 predefined landmarks is what is provided with this face Service uh another interesting thing is face attribute so you can uh check whether they're wearing access accessories so think like earrings or lip rings uh determine its age uh the blurriness of the image uh what kind of emotion is being uh experienced the exposure of the image you know the contrast uh facial hair gender glasses uh your hair in general the head pose there's a lot of information around that makeup which seems to be limited like when we ran it here in the lab all we got back was eye makeup and lip makeup but hey we get some information whether they're wearing a mask uh noise so whether there's artifacts like visual artifacts or occlusion so whether an object is blocking parts of the face and then they simply have a Boolean value for whether the person's smiling or not which I assume is a very common component so that's pretty much all we really need to know about the faith service and there you go all right so let's move on to the face service so just go ahead and double click there on the left hand side and what we'll do is work our way from the top so the first thing we need to do is make sure that we have the computer vision installed so the face service is part of the computer vision API and once that is done we'll go ahead and uh do our Imports very similar to the last one but here we're using the face client we're still using the Cog cognitive service credentials we will populate our keys we make the face client and authenticate and we're going to use the same image we used um uh prior with our computer vision so the data one there and we'll go ahead and print out the results and so we get an object back so it's not very clear what it is but here if we hit show okay here it's data and it's identifying the face ID so going through this code so we're just saying open the image we're going to uh set up our figure for plotting uh it's going to say well how many faces did it detect in the photo and so here it says detected one face it will iterate through it and then we will create a bounding box around the images we can do that because it returns back the face rectangle so we get a top left right Etc and uh we will we draw that Wrangle on top so we have magenta I could change it to like three if I wanted to uh I don't know what the other colors are so I'm not even going to try but yeah there it is and then we annotate with the face ID that's the unique identifier for the face and then we show the image okay so that's one and then if we wanted to get more detailed information like attribute such as age emotion makeup or gender uh this resolution image wasn't large enough so I had to find a different image and and do that so that's one thing you need to know as if it's large enough it won't process it so we're just loading data large very similar process but it is uh the same thing detect with stream but now we're passing in um return face attributes and so here we're saying the tributes we want uh and there's that list and we went through it in the lecture content and so here we'll go ahead and run this and so we're getting more information so that magenta line is a bit hard to see I'm just going to increase that to three okay still really hard to see but that's okay so approximate age 44 I think the actor was a bit younger than that uh uh data technically is male presenting but he's an Android so he doesn't necessarily have a gender I suppose he actually is wearing a lot of makeup but all it detects is it I guess it's only particular on the lips and the eyes so it says he doesn't have makeup so maybe there's like color you know like ey Shadow stuff maybe it would detect that in terms of personality I like how it's he's a a 00 2% Sab but he's neutral right uh so just going through the code here very quickly so again it's the number of faces so it detected one face uh and then we draw a bounding box around the face for the detected attributes it's uh returned back in uh the data here so we just say get the face attributes turn it into a dictionary and then we can just uh get those values and uh iterate over it so that's as complicated as it is um and so there we go hey this is Andrew Brown in this video we're going to just do cleanup after all this uh AIML work we just want to make sure nothing is second around that's going to cost us any money my approach to clean up is generally going over to Resource groups so I I go here because everything's created in a resource Group here and we can just kind of narrow down what it is uh that we need to get rid of so definitely AI managed workspace this one here um but yeah yours might look a little bit different based on how you name it but just carefully look through uh what you've created and so I'm just carefully going through here uh I don't think this is mine but I'm going to ignore that because I don't think I did any Lura training but I'll get rid of it anyway open AI studio right and go ahead and just delete your resources so nothing super complicated here again just a to remind you to clean up your resources so you don't have any unexpected spend but for the most part part everything we ran um we were pretty good about uh shutting off so I don't think that's much of an issue delete Resource Group here we go ahead and just continue down here yeah I don't think it's that big of a deal here is another one and we'll delete this one there we go and I'm just going to confirm everything deleted just in case anything hangs here want to tell you hey this hanged we got to fix this I think it's all going to delete but for this video I'm going to confirm uh here and just wait till everything's deleted okay all right let's see if those are all deleted I just refreshed this one so that one is done this one is done this one is not 100% done maybees this one that one is done this one is done there we go so the only one I'm waiting on is this one so hopefully everything's stuck here so we're g to again just keep waiting here till this is done all right so looking here there actually was a failure so it's a good thing that I was very thorough here with us here says failed to delete the resource Group Azure AI Studio Hub deletion Resource Group failed with identifiers for AI Andrew etc etc cannot be deleted the provision state is whatever so there's something it does not like um it appears to be uh 196 so it's this one could be the other one as well but there's something here it doesn't like so I'm going to go into here and take a look at what there is this is I think where we trained our model and so this is where we might be having some trouble so we'll go down to deployments here and so we have this custom deployed model so I'm going to go ahead and just delete this and uh it's not fast deleting here so yep there we go so I wonder if I could checkbox both of these nope so I'll just delete these at a time not exactly sure what's causing this issue we'll go to data files we might have something here do we have any data files we do we'll go ahead and delete those as well good um what interesting is this Vector store down here now we never utilize this anywhere but this could have been a interesting thing that we could have utilized this almost seems like seems like this could have been like a a simpler way of using Azure EI search but they're always adding things here so I'm not too worried about it let's go over to the no it seems like everything here let's go one level up let's see if there's any connections so normally it would show like as connections here I'm not exactly seeing let's click into this again and hm because this is azure AI studio and usually it has projects but there's no hubs here so this should in theory now delete so we're going to try to get rid of this again and close this out here so I'm G to actually go over to Azure Studio tab here and I'm going to see if I can manually delete this go over here and not exactly I to click into it here here we go delete uh yep we'll delete it same story here I want to try to delete this one into it go ahead and attempt to delete this as one as well okay be back here in just a bit see if this works all right let's take a look here and see if these resources have successfully deleted and m not sure if they deleted nope almost so one is still giving us a little bit of trouble just take a look here and underly user data so failed to delete the resource can go in here there's something it doesn't like I'm not sure we'll go back here and over to Azure AI Studio Hub and we'll go into here and so what are we looking for there's something here that it doesn't like um and all I can think of is to go back into the Hub and try to find or the studio and try to find something to delete so we have no data files we have we have we have a couple deployments so we try ahead and delete those I'm not sure if that would fix our problem so anything we can get rid of let's get rid of go to data files nothing here Vector stores I was thinking there would be something like with connections but I don't see any connections here overview yeah nothing over there go back a step can I delete it from here no no no no so I'm going to attempt to delete this one more time because it seems like it's almost gone and that was the only stuff that was sticking around here so I cannot imagine uh there being much of anything else here like there's nothing in here that's going to cause a spend so we can't delete it's not that big of a deal but I hate when there's just stuff lingering around here so let's go ahead and try this again delete again yes and just opening up here trying to think if there's anything else oh it deleted perfectly so we're all cleaned up if you want to clean up that last uh one here you can go ahead and do that but this is now considered done and I will see you in the next one so yeah sometimes you just got to keep deleting deleting ciao